{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Introduction to utPLSQL \u00b6 utPLSQL is a Unit Testing framework for Oracle PL/SQL. The framework follows industry standards and best patterns of modern Unit Testing frameworks like JUnit and RSpec User Guide Installation Getting Started Annotations Expectations Running unit tests Testing best pracitces Upgrade utPLSQL Reporting Using reporters Reporting errors Code coverage Cheat-sheet About Project Details License Support Authors Demo project \u00b6 Have a look at our demo project . It uses Travis CI to build on every commit, runs all tests, publishes test results and code coverage to SonarQube . Three steps \u00b6 With just three simple steps you can define and run your unit tests for PLSQL code. Install the utPLSQL framework Create Unit Tests to for the code Run the tests Here is how you can simply create tested code, unit tests and execute the tests using SQL Developer Check out the sections on annotations and expectations to see how to define your tests. Command line \u00b6 The ut_run (for linux/unix) and ut_run.bat (for windows) are simple yet powerful. They can provide output from the tests on the fly. You can also use it to have coloured outputs. Look into utPLSQL-sql-cli project to see more. Coverage \u00b6 If you want to have code coverage gathered on your code , it's best to use ut_run to execute your tests with multiple reporters and have both test execution report as well as coverage report saved to a file. Check out the coverage documentation for options of coverage reporting","title":"Introduction to utPLSQL"},{"location":"index.html#introduction-to-utplsql","text":"utPLSQL is a Unit Testing framework for Oracle PL/SQL. The framework follows industry standards and best patterns of modern Unit Testing frameworks like JUnit and RSpec User Guide Installation Getting Started Annotations Expectations Running unit tests Testing best pracitces Upgrade utPLSQL Reporting Using reporters Reporting errors Code coverage Cheat-sheet About Project Details License Support Authors","title":"Introduction to utPLSQL"},{"location":"index.html#demo-project","text":"Have a look at our demo project . It uses Travis CI to build on every commit, runs all tests, publishes test results and code coverage to SonarQube .","title":"Demo project"},{"location":"index.html#three-steps","text":"With just three simple steps you can define and run your unit tests for PLSQL code. Install the utPLSQL framework Create Unit Tests to for the code Run the tests Here is how you can simply create tested code, unit tests and execute the tests using SQL Developer Check out the sections on annotations and expectations to see how to define your tests.","title":"Three steps"},{"location":"index.html#command-line","text":"The ut_run (for linux/unix) and ut_run.bat (for windows) are simple yet powerful. They can provide output from the tests on the fly. You can also use it to have coloured outputs. Look into utPLSQL-sql-cli project to see more.","title":"Command line"},{"location":"index.html#coverage","text":"If you want to have code coverage gathered on your code , it's best to use ut_run to execute your tests with multiple reporters and have both test execution report as well as coverage report saved to a file. Check out the coverage documentation for options of coverage reporting","title":"Coverage"},{"location":"about/authors.html","text":"utPLSQL v3 Major Contributors \u00b6 Listed Alphabetically Name GitHub account David Pyke Shoelace Jacek Gebal jgebal Pavel Kaplya Pazus Robert Love rlove Vinicius Avellar viniciusam Many thanks to all the contributors Special thanks to prior major contributors \u00b6 Steven Feuerstein - Original Author Chris Rimmer Patrick Barel Paul Walker","title":"Authors"},{"location":"about/authors.html#utplsql-v3-major-contributors","text":"Listed Alphabetically Name GitHub account David Pyke Shoelace Jacek Gebal jgebal Pavel Kaplya Pazus Robert Love rlove Vinicius Avellar viniciusam Many thanks to all the contributors","title":"utPLSQL v3 Major Contributors"},{"location":"about/authors.html#special-thanks-to-prior-major-contributors","text":"Steven Feuerstein - Original Author Chris Rimmer Patrick Barel Paul Walker","title":"Special thanks to prior major contributors"},{"location":"about/license.html","text":"Version Information \u00b6 utPLSQL version 3 is licensed under Apache 2.0 External code used in the development of this project, but is not required for use. Tool License Purpose Travis-Oracle ISC Install Oracle for Travis Builds mkDocs BSD Produce HTML version of documentation Note: Version 1 & 2 of utPLSQL were licensed under GPL, version 3 was a complete rewrite from scratch which a allowed us to change the license to be more permissive.","title":"License"},{"location":"about/license.html#version-information","text":"utPLSQL version 3 is licensed under Apache 2.0 External code used in the development of this project, but is not required for use. Tool License Purpose Travis-Oracle ISC Install Oracle for Travis Builds mkDocs BSD Produce HTML version of documentation Note: Version 1 & 2 of utPLSQL were licensed under GPL, version 3 was a complete rewrite from scratch which a allowed us to change the license to be more permissive.","title":"Version Information"},{"location":"about/project-details.html","text":"utPLSQL Project Details \u00b6 utPLSQL is open source project hosted on GitHub . Contributions, help and constructive feedback is always appreciated. If you are interested in helping please read our contributing guide","title":"Project Details"},{"location":"about/project-details.html#utplsql-project-details","text":"utPLSQL is open source project hosted on GitHub . Contributions, help and constructive feedback is always appreciated. If you are interested in helping please read our contributing guide","title":"utPLSQL Project Details"},{"location":"about/support.html","text":"How to get support \u00b6 Feel free to post questions, bugs or issues in the issues area of GitHub Join developers at the utPLSQL team on Slack","title":"Support"},{"location":"about/support.html#how-to-get-support","text":"Feel free to post questions, bugs or issues in the issues area of GitHub Join developers at the utPLSQL team on Slack","title":"How to get support"},{"location":"userguide/annotations.html","text":"Annotations \u00b6 Annotations are used to configure tests and suites in a declarative way similar to modern OOP languages. This way, test configuration is stored along with the test logic inside the test package. No configuration files or tables are needed. The annotations names are based on popular testing frameworks such as jUnit. The framework runner searches for all the suitable annotated packages, automatically configures suites, forms suites hierarchy, executes it and reports results in specified formats. Annotations are interpreted only in package specification and are case-insensitive. It is recommended however, to use the lower-case annotations as described in documentation. There are two places where annotations may appear: at the beginning of the package specification ( %suite , %suitepath etc) right before a procedure ( %test , %beforeall , %beforeeach etc). Package level annotations need to be separated by at least one empty line from the underlying procedure annotations. Procedure annotations are defined right before the procedure they reference, no empty lines are allowed. If a package specification contains %suite annotation, it is treated as a test package and processed by the framework. Some annotations accept parameters like %suite , %test and %displayname . The parameters for annotations need to be placed in brackets. Values for parameters should be provided without any quotation marks. Example of an annotated test package \u00b6 create or replace package test_pkg is -- %suite(Name of suite) -- %suitepath(all.globaltests) -- %beforeall procedure global_setup ; -- %afterall procedure global_cleanup ; /* Such comments are allowed */ -- %test -- %displayname(Name of a test) procedure some_test ; -- %test(Name of another test) -- %beforetest(setup_another_test) -- %aftertest(cleanup_another_test) procedure another_test ; -- %test -- %displayname(Name of test) -- %disabled procedure disabled_test ; -- %test(Name of test) -- %rollback(manual) procedure no_transaction_control_test ; procedure setup_another_test ; procedure cleanup_another_test ; -- %beforeeach procedure test_setup ; -- %aftereach procedure test_cleanup ; end test_pkg ; Supported annotations \u00b6 Annotation Level Description %suite(<description>) Package Mandatory. Marks package as a test suite. Optional suite description can be provided (see displayname ). %suitepath(<path>) Package Similar to java package. The annotation allows logical grouping of suites into hierarchies. %displayname(<description>) Package/procedure Human-readable and meaningful description of a suite/test. %displayname(Name of the suite/test) . The annotation is provided for flexibility and convenience only. It has exactly the same meaning as <descriotion> in test and suite annotations. If description is provided using both suite / test and displayname , then the one defined as last takes precedence. %test(<description>) Procedure Denotes that the annotated procedure is a unit test procedure. Optional test description can by provided (see displayname ). %beforeall Procedure Denotes that the annotated procedure should be executed once before all elements of the suite. %afterall Procedure Denotes that the annotated procedure should be executed once after all elements of the suite. %beforeeach Procedure Denotes that the annotated procedure should be executed before each %test procedure in the suite. %aftereach Procedure Denotes that the annotated procedure should be executed after each %test procedure in the suite. %beforetest(<procedure_name>) Procedure Denotes that mentioned procedure should be executed before the annotated %test procedure. %aftertest(<procedure_name>) Procedure Denotes that mentioned procedure should be executed after the annotated %test procedure. %rollback(<type>) Package/procedure Defines transaction control. Supported values: auto (default) - A savepoint is created before invocation of each \"before block\" is and a rollback to specific savepoint is issued after each \"after\" block; manual - rollback is never issued automatically. Property can be overridden for child element (test in suite) %disabled Package/procedure Used to disable a suite or a test. Disabled suites/tests do not get executed, they are however marked and reported as disabled in a test run. Suitepath concept \u00b6 It is very likely that the application for which you are going to introduce tests consists of many different packages or procedures/functions. Usually procedures can be logically grouped inside a package, there also might be several logical groups of procedure in a single package or even packages themselves might relate to a common module. Let's say you have a complex insurance application that deals with policies, claims and payments. The payment module contains several packages for payment recognition, charging, planning etc. The payment recognition module among others contains a complex recognize_payment procedure that associates received money to the policies. If you want to create tests for your application it is recommended to structure your tests similarly to the logical structure of your application. So you end up with something like: * Integration tests * Policy tests * Claim tests * Payment tests * Payments recognition * Payments set off * Payouts The %suitepath annotation is used for such grouping. Even though test packages are defined in a flat structure the %suitepath is used by the framework to form them into a hierarchical structure. Your payments recognition test package might look like: create or replace package test_payment_recognition as -- %suite(Payment recognition tests) -- %suitepath(payments) -- %test(Recognize payment by policy number) procedure test_recognize_by_num ; -- %test -- %displayname(Recognize payment by payment purpose) procedure test_recognize_by_purpose ; -- %test(Recognize payment by customer) procedure test_recognize_by_customer ; end test_payment_recognition ; And payments set off test package: create or replace package test_payment_set_off as -- %suite(Payment set off tests) -- %suitepath(payments) -- %test(Set off creation test) procedure test_create_set_off ; -- %test -- %displayname(Set off annulation test) procedure test_annulate_set_off ; end test_payment_set_off ; When you execute tests for your application, the framework constructs a test suite for each test package. Then it combines suites into grouping suites by the %suitepath annotation value so that the fully qualified path to the recognize_by_num procedure is USER:payments.test_payment_recognition.test_recognize_by_num . If any of its expectations fails then the test is marked as failed, also the test_payment_recognition suite, the parent suite payments and the whole run is marked as failed. The test report indicates which expectation has failed on the payments module. The payments recognition submodule is causing the failure as recognize_by_num has not met the expectations of the test. Grouping tests into modules and submodules using the %suitepath annotation allows you to logically organize your project's flat structure of packages into functional groups. An additional advantage of such grouping is the fact that every element level of the grouping can be an actual unit test package containing a common module level setup for all of the submodules. So in addition to the packages mentioned above you could have the following package. create or replace package payments as -- %suite(Payments) -- %beforeall procedure set_common_payments_data ; -- %afterall procedure reset_common_paymnets_data ; end payments ; A %suitepath can be provided in three ways: * schema - execute all tests in the schema * [schema]:suite1[.suite2][.suite3]...[.procedure] - execute all tests in all suites from suite1[.suite2][.suite3]...[.procedure] path. If schema is not provided, then the current schema is used. Example: :all.rooms_tests * [schema.]package[.procedure] - execute all tests in the specified test package. The whole hierarchy of suites in the schema is built before all before/after hooks or part suites for the provided suite package are executed as well. Example: tests.test_contact.test_last_name_validator or simply test_contact.test_last_name_validator if tests is the current schema. Using automatic rollbacks in tests \u00b6 By default, changes performed by every setup, cleanup and test procedure are isolated by savepoints. This solution is suitable for use-cases where the code that is getting tested as well as the unit tests themselves do not use transaction control (commit/rollback) or DDL commands. In general, your unit tests should not use transaction control as long as the code you are testing is not using it too. Keeping the transactions uncommitted allows your changes to be isolated and the execution of tests does not impact others who might be using a shared development database. If you are in a situation where the code you are testing uses transaction control (common case with ETL code), then your tests probably should not use the default automatic transaction control. In that case use the annotation -- %rollback(manual) on the suite level to disable automatic transaction control for the entire suite. If you are using nested suites, you need to make sure that the entire suite all the way to the root is using manual transaction control. It is possible with utPLSQL to change the transaction control on individual suites or tests that are part of complex suite. It is strongly recommended not to have mixed transaction control in a suite. Mixed transaction control settings will not work properly when your suites are using shared setup/cleanup with beforeall, afterall, beforeeach or aftereach annotations. Your suite will most likely fail with error or warning on execution. Some of the automatic rollbacks will probably fail to execute depending on the configuration you have. In some cases it is necessary to perform DDL as part of setup or cleanup for the tests. It is recommended to move such DDL statements to a procedure with pragma autonomous_transaction to eliminate implicit commits in the main session that is executing all your tests. Doing so allows your tests to use the framework's automatic transaction control and releases you from the burden of manual cleanup of data that was created or modified by test execution. When you are testing code that performs explicit or implicit commits, you may set the test procedure to run as an autonomous transaction with pragma autonomous_transaction . Keep in mind that when your tests runs in autonomous transaction it will not see the data prepared in setup procedure unless the setup procedure committed the changes. Order of execution \u00b6 When processing the test suite test_pkg defined in Example of annotated test package , the order of execution will be as follows. create a savepoint 'beforeall' execute global_setup create savepoint 'beforeeach' execute test_setup execute some_test execute test_cleanup rollback to savepoint 'beforeeach' create savepoint 'beforeeach' execute test_setup execute setup_another_test execute another_test execute cleanup_another_test execute test_cleanup rollback to savepoint 'beforeeach' mark disabled_test as disabled execute test_setup execute no_transaction_control_test execute test_cleanup execute global_cleanup rollback to savepoint 'beforeall' Annotation cache \u00b6 utPLSQL needs to scan sources of package specifications to identify and parse annotations. To improve framework startup time, specially when dealing with database users owning large amount of packages the framework has build-in persistent cache for annotations. Cache is checked for staleness and refreshed automatically on every run. The initial startup of utPLSQL for a schema will take longer than consecutive executions. If you're in situation, where your database is controlled via CI/CD server and gets refreshed/wiped before each run of your tests, consider building upfront and creating the snapshot of our database after the cache was refreshed. To build annotation cache without actually invoking any tests, call ut_runner.rebuild_annotation_cache(a_object_owner, a_object_type) sql block for every unit test owner that you want to have annotations cache prebuilt. Example: exec ut_runner . rebuild_annotation_cache ( 'HR' , 'PACKAGE' ); To purge annotations cache call: exec ut_runner . purge_cache ( 'HR' , 'PACKAGE' );","title":"Annotations"},{"location":"userguide/annotations.html#annotations","text":"Annotations are used to configure tests and suites in a declarative way similar to modern OOP languages. This way, test configuration is stored along with the test logic inside the test package. No configuration files or tables are needed. The annotations names are based on popular testing frameworks such as jUnit. The framework runner searches for all the suitable annotated packages, automatically configures suites, forms suites hierarchy, executes it and reports results in specified formats. Annotations are interpreted only in package specification and are case-insensitive. It is recommended however, to use the lower-case annotations as described in documentation. There are two places where annotations may appear: at the beginning of the package specification ( %suite , %suitepath etc) right before a procedure ( %test , %beforeall , %beforeeach etc). Package level annotations need to be separated by at least one empty line from the underlying procedure annotations. Procedure annotations are defined right before the procedure they reference, no empty lines are allowed. If a package specification contains %suite annotation, it is treated as a test package and processed by the framework. Some annotations accept parameters like %suite , %test and %displayname . The parameters for annotations need to be placed in brackets. Values for parameters should be provided without any quotation marks.","title":"Annotations"},{"location":"userguide/annotations.html#example-of-an-annotated-test-package","text":"create or replace package test_pkg is -- %suite(Name of suite) -- %suitepath(all.globaltests) -- %beforeall procedure global_setup ; -- %afterall procedure global_cleanup ; /* Such comments are allowed */ -- %test -- %displayname(Name of a test) procedure some_test ; -- %test(Name of another test) -- %beforetest(setup_another_test) -- %aftertest(cleanup_another_test) procedure another_test ; -- %test -- %displayname(Name of test) -- %disabled procedure disabled_test ; -- %test(Name of test) -- %rollback(manual) procedure no_transaction_control_test ; procedure setup_another_test ; procedure cleanup_another_test ; -- %beforeeach procedure test_setup ; -- %aftereach procedure test_cleanup ; end test_pkg ;","title":"Example of an annotated test package"},{"location":"userguide/annotations.html#supported-annotations","text":"Annotation Level Description %suite(<description>) Package Mandatory. Marks package as a test suite. Optional suite description can be provided (see displayname ). %suitepath(<path>) Package Similar to java package. The annotation allows logical grouping of suites into hierarchies. %displayname(<description>) Package/procedure Human-readable and meaningful description of a suite/test. %displayname(Name of the suite/test) . The annotation is provided for flexibility and convenience only. It has exactly the same meaning as <descriotion> in test and suite annotations. If description is provided using both suite / test and displayname , then the one defined as last takes precedence. %test(<description>) Procedure Denotes that the annotated procedure is a unit test procedure. Optional test description can by provided (see displayname ). %beforeall Procedure Denotes that the annotated procedure should be executed once before all elements of the suite. %afterall Procedure Denotes that the annotated procedure should be executed once after all elements of the suite. %beforeeach Procedure Denotes that the annotated procedure should be executed before each %test procedure in the suite. %aftereach Procedure Denotes that the annotated procedure should be executed after each %test procedure in the suite. %beforetest(<procedure_name>) Procedure Denotes that mentioned procedure should be executed before the annotated %test procedure. %aftertest(<procedure_name>) Procedure Denotes that mentioned procedure should be executed after the annotated %test procedure. %rollback(<type>) Package/procedure Defines transaction control. Supported values: auto (default) - A savepoint is created before invocation of each \"before block\" is and a rollback to specific savepoint is issued after each \"after\" block; manual - rollback is never issued automatically. Property can be overridden for child element (test in suite) %disabled Package/procedure Used to disable a suite or a test. Disabled suites/tests do not get executed, they are however marked and reported as disabled in a test run.","title":"Supported annotations"},{"location":"userguide/annotations.html#suitepath-concept","text":"It is very likely that the application for which you are going to introduce tests consists of many different packages or procedures/functions. Usually procedures can be logically grouped inside a package, there also might be several logical groups of procedure in a single package or even packages themselves might relate to a common module. Let's say you have a complex insurance application that deals with policies, claims and payments. The payment module contains several packages for payment recognition, charging, planning etc. The payment recognition module among others contains a complex recognize_payment procedure that associates received money to the policies. If you want to create tests for your application it is recommended to structure your tests similarly to the logical structure of your application. So you end up with something like: * Integration tests * Policy tests * Claim tests * Payment tests * Payments recognition * Payments set off * Payouts The %suitepath annotation is used for such grouping. Even though test packages are defined in a flat structure the %suitepath is used by the framework to form them into a hierarchical structure. Your payments recognition test package might look like: create or replace package test_payment_recognition as -- %suite(Payment recognition tests) -- %suitepath(payments) -- %test(Recognize payment by policy number) procedure test_recognize_by_num ; -- %test -- %displayname(Recognize payment by payment purpose) procedure test_recognize_by_purpose ; -- %test(Recognize payment by customer) procedure test_recognize_by_customer ; end test_payment_recognition ; And payments set off test package: create or replace package test_payment_set_off as -- %suite(Payment set off tests) -- %suitepath(payments) -- %test(Set off creation test) procedure test_create_set_off ; -- %test -- %displayname(Set off annulation test) procedure test_annulate_set_off ; end test_payment_set_off ; When you execute tests for your application, the framework constructs a test suite for each test package. Then it combines suites into grouping suites by the %suitepath annotation value so that the fully qualified path to the recognize_by_num procedure is USER:payments.test_payment_recognition.test_recognize_by_num . If any of its expectations fails then the test is marked as failed, also the test_payment_recognition suite, the parent suite payments and the whole run is marked as failed. The test report indicates which expectation has failed on the payments module. The payments recognition submodule is causing the failure as recognize_by_num has not met the expectations of the test. Grouping tests into modules and submodules using the %suitepath annotation allows you to logically organize your project's flat structure of packages into functional groups. An additional advantage of such grouping is the fact that every element level of the grouping can be an actual unit test package containing a common module level setup for all of the submodules. So in addition to the packages mentioned above you could have the following package. create or replace package payments as -- %suite(Payments) -- %beforeall procedure set_common_payments_data ; -- %afterall procedure reset_common_paymnets_data ; end payments ; A %suitepath can be provided in three ways: * schema - execute all tests in the schema * [schema]:suite1[.suite2][.suite3]...[.procedure] - execute all tests in all suites from suite1[.suite2][.suite3]...[.procedure] path. If schema is not provided, then the current schema is used. Example: :all.rooms_tests * [schema.]package[.procedure] - execute all tests in the specified test package. The whole hierarchy of suites in the schema is built before all before/after hooks or part suites for the provided suite package are executed as well. Example: tests.test_contact.test_last_name_validator or simply test_contact.test_last_name_validator if tests is the current schema.","title":"Suitepath concept"},{"location":"userguide/annotations.html#using-automatic-rollbacks-in-tests","text":"By default, changes performed by every setup, cleanup and test procedure are isolated by savepoints. This solution is suitable for use-cases where the code that is getting tested as well as the unit tests themselves do not use transaction control (commit/rollback) or DDL commands. In general, your unit tests should not use transaction control as long as the code you are testing is not using it too. Keeping the transactions uncommitted allows your changes to be isolated and the execution of tests does not impact others who might be using a shared development database. If you are in a situation where the code you are testing uses transaction control (common case with ETL code), then your tests probably should not use the default automatic transaction control. In that case use the annotation -- %rollback(manual) on the suite level to disable automatic transaction control for the entire suite. If you are using nested suites, you need to make sure that the entire suite all the way to the root is using manual transaction control. It is possible with utPLSQL to change the transaction control on individual suites or tests that are part of complex suite. It is strongly recommended not to have mixed transaction control in a suite. Mixed transaction control settings will not work properly when your suites are using shared setup/cleanup with beforeall, afterall, beforeeach or aftereach annotations. Your suite will most likely fail with error or warning on execution. Some of the automatic rollbacks will probably fail to execute depending on the configuration you have. In some cases it is necessary to perform DDL as part of setup or cleanup for the tests. It is recommended to move such DDL statements to a procedure with pragma autonomous_transaction to eliminate implicit commits in the main session that is executing all your tests. Doing so allows your tests to use the framework's automatic transaction control and releases you from the burden of manual cleanup of data that was created or modified by test execution. When you are testing code that performs explicit or implicit commits, you may set the test procedure to run as an autonomous transaction with pragma autonomous_transaction . Keep in mind that when your tests runs in autonomous transaction it will not see the data prepared in setup procedure unless the setup procedure committed the changes.","title":"Using automatic rollbacks in tests"},{"location":"userguide/annotations.html#order-of-execution","text":"When processing the test suite test_pkg defined in Example of annotated test package , the order of execution will be as follows. create a savepoint 'beforeall' execute global_setup create savepoint 'beforeeach' execute test_setup execute some_test execute test_cleanup rollback to savepoint 'beforeeach' create savepoint 'beforeeach' execute test_setup execute setup_another_test execute another_test execute cleanup_another_test execute test_cleanup rollback to savepoint 'beforeeach' mark disabled_test as disabled execute test_setup execute no_transaction_control_test execute test_cleanup execute global_cleanup rollback to savepoint 'beforeall'","title":"Order of execution"},{"location":"userguide/annotations.html#annotation-cache","text":"utPLSQL needs to scan sources of package specifications to identify and parse annotations. To improve framework startup time, specially when dealing with database users owning large amount of packages the framework has build-in persistent cache for annotations. Cache is checked for staleness and refreshed automatically on every run. The initial startup of utPLSQL for a schema will take longer than consecutive executions. If you're in situation, where your database is controlled via CI/CD server and gets refreshed/wiped before each run of your tests, consider building upfront and creating the snapshot of our database after the cache was refreshed. To build annotation cache without actually invoking any tests, call ut_runner.rebuild_annotation_cache(a_object_owner, a_object_type) sql block for every unit test owner that you want to have annotations cache prebuilt. Example: exec ut_runner . rebuild_annotation_cache ( 'HR' , 'PACKAGE' ); To purge annotations cache call: exec ut_runner . purge_cache ( 'HR' , 'PACKAGE' );","title":"Annotation cache"},{"location":"userguide/best-practices.html","text":"Best Practices \u00b6 The following are best practices we at utPLSQL have learned about PL/SQL and Unit Testing. Test Isolation and Dependency \u00b6 Tests should not depend on a specific order to run Tests should not depend on other tests to execute Tests should not depend on specific database state, they should setup the expected state before being run Tests should keep the environment unchanged post execution Writing tests \u00b6 Tests should not mimic / duplicate the logic of tested code Tests should contain zero logic (or as close to zero as possible) The 3A rule: Arrange (setup inputs/data/environment for the tested code) Act (execute code under test) Assert (validate the outcomes of the execution) Each tested procedure/function/trigger (code block) should have more than one test Each test should check only one behavior (one requirement) of the code block under test Tests should be maintained as thoroughly as production code Every test needs to be built so that it can fail, tests that do not fail when needed are useless Gaining value from the tests \u00b6 Tests are only valuable if they are executed frequently; ideally with every change to the project code Tests need to run very fast; the slower the tests, the longer you wait. Build tests with performance in mind (do you really need to have 10k rows to run the tests?) Tests that are executed infrequently can quickly become stale and end up adding overhead rather than value. Maintain tests as you would maintain code. Tests that are failing need to be addressed immediately. How can you trust your tests when 139 of 1000 tests are failing for a month? Will you recognise each time that it is still the same 139 tests? Tests are not for production \u00b6 Tests will generate and operate on fake data. They might insert, update and delete data. You don't want tests to run on a production database and affect real life data. Tests and their relationship to code under test \u00b6 Tests and the code under test should be in separate packages. This is a fundamental separation of responsibilities. It is common for test code to be in the same schema as the tested code. This removes the need to manage privileges for the tests. Version Control \u00b6 Use a version control system for your code. Don't just trust the database for code storage. This includes both the code under test, and the unit tests you develop as well. Treat the database as a target/destination for your code, not as a source of it.","title":"Testing best pracitces"},{"location":"userguide/best-practices.html#best-practices","text":"The following are best practices we at utPLSQL have learned about PL/SQL and Unit Testing.","title":"Best Practices"},{"location":"userguide/best-practices.html#test-isolation-and-dependency","text":"Tests should not depend on a specific order to run Tests should not depend on other tests to execute Tests should not depend on specific database state, they should setup the expected state before being run Tests should keep the environment unchanged post execution","title":"Test Isolation and Dependency"},{"location":"userguide/best-practices.html#writing-tests","text":"Tests should not mimic / duplicate the logic of tested code Tests should contain zero logic (or as close to zero as possible) The 3A rule: Arrange (setup inputs/data/environment for the tested code) Act (execute code under test) Assert (validate the outcomes of the execution) Each tested procedure/function/trigger (code block) should have more than one test Each test should check only one behavior (one requirement) of the code block under test Tests should be maintained as thoroughly as production code Every test needs to be built so that it can fail, tests that do not fail when needed are useless","title":"Writing tests"},{"location":"userguide/best-practices.html#gaining-value-from-the-tests","text":"Tests are only valuable if they are executed frequently; ideally with every change to the project code Tests need to run very fast; the slower the tests, the longer you wait. Build tests with performance in mind (do you really need to have 10k rows to run the tests?) Tests that are executed infrequently can quickly become stale and end up adding overhead rather than value. Maintain tests as you would maintain code. Tests that are failing need to be addressed immediately. How can you trust your tests when 139 of 1000 tests are failing for a month? Will you recognise each time that it is still the same 139 tests?","title":"Gaining value from the tests"},{"location":"userguide/best-practices.html#tests-are-not-for-production","text":"Tests will generate and operate on fake data. They might insert, update and delete data. You don't want tests to run on a production database and affect real life data.","title":"Tests are not for production"},{"location":"userguide/best-practices.html#tests-and-their-relationship-to-code-under-test","text":"Tests and the code under test should be in separate packages. This is a fundamental separation of responsibilities. It is common for test code to be in the same schema as the tested code. This removes the need to manage privileges for the tests.","title":"Tests and their relationship to code under test"},{"location":"userguide/best-practices.html#version-control","text":"Use a version control system for your code. Don't just trust the database for code storage. This includes both the code under test, and the unit tests you develop as well. Treat the database as a target/destination for your code, not as a source of it.","title":"Version Control"},{"location":"userguide/coverage.html","text":"Coverage \u00b6 utPLSQL comes with build-in coverage reporting engine. The code coverage reporting is based off DBMS_PROFILER package. Code coverage is gathered for the following source types: * package bodies * type bodies * triggers * stored procedures * stored functions Note: The package specifications and type specifications are explicitly excluded from code coverage analysis.This limitation is introduced to avoid false-negatives. Most of the package specifications don't contain executable code. The only exception is initialization of global constants and variables in package specification.Since, most of package specifications are not executable at all, there is no information available on the number of lines covered and those would eb reported as 0% covered, which is not desired. To obtain information about code coverage of your Unit Tests, all you need to do is run your unit tests with one of build-in code coverage reporters. Following code coverage reporters are supplied with utPLSQL: * ut_coverage_html_reporter - generates a HTML coverage report providing summary and detailed information on code coverage. The html reporter is based on open-source simplecov-html reporter for Ruby. It includes source code of the code that was covered (if possible) * ut_coveralls_reporter - generates a Coveralls compatible JSON coverage report providing detailed information on code coverage with line numbers. This coverage report is designed to be consumed by cloud services like coveralls * ut_coverage_sonar_reporter - generates a Sonar Compatible XML coverage report providing detailed information on code coverage with line numbers. This coverage report is designed to be consumed by services like sonarqube/sonarcloud Security model \u00b6 Code coverage is using DBMS_PROFILER to gather information about execution of code under test and therefore follows the DBMS_PROFILER's Security Model In order to be able to gather coverage information, user executing unit tests needs to be either: * Owner of the code that is tested * Have the following privileges to be able to gather coverage on code owned by other users: * create any procedure system privilege * execute privilege on the code that is tested (not only the unit tests) or execute any procedure system privilege If you have execute privilege on the code that are tested, but do not have create any procedure system privilege, the code that is tested will be reported as not covered (coverage = 0%). If you have execute privilege only on the unit tests, but do not have execute privilege on the code that is tested, the code will not be reported by coverage - as if it did not exist in the database. If the code that is testes is complied as NATIVE, the code coverage will not be reported as well. Running unite tests with coverage \u00b6 Using code coverage functionality is as easy as using any other reporter for utPLSQL project. All you need to do is run your tests from your preferred SQL tool and save the outcomes of reporter to a file. All you need to do, is pass the constructor of the reporter to your ut.run Example: begin ut . run ( ut_coverage_html_reporter ()); end ; / Executes all unit tests in current schema, gather information about code coverage and output the html text into DBMS_OUTPUT. The ut_coverage_html_reporter will produce a interactive HTML report. You may see a sample of code coverage for utPLSQL project here The report provides a summary information with list of source code that was expected to be covered. The report allow to navigate to every source and inspect line by line coverage. Coverage reporting options \u00b6 By default the database schema/schemes containing the tests that were executed during the run, are fully reported by coverage reporter. All valid unit tests are excluded from the report regardless if they were invoked or not. This way the coverage report is not affected by presence of tests and contains only the tested code. The default behavior of coverage reporters can be altered, depending on your needs. Including/excluding objects in coverage reports \u00b6 The most basic options are the include/exclude objects lists. You may specify both include and exclude objects lists to specify which objects are to be included in the report and which are to be excluded. Both of those options are meant to be used to narrow down the scope of unit test runs, that is broad by default. Example: exec ut . run ( 'ut3_user.test_award_bonus' , ut_coverage_html_reporter (), a_include_objects => ut_varchar2_list ( 'ut3_user.award_bonus' )); Executes test test_award_bonus and gather coverage only on object ut3_user.award_bonus Alternatively you could run: exec ut . run ( 'ut3_user.test_award_bonus' , ut_coverage_html_reporter (), a_exclude_objects => ut_varchar2_list ( 'ut3_user.betwnstr' )); Executes test test_award_bonus and gather on all objects in schema ut3_user except valid unit test objects and object betwnstr that schema. You can also combine the parameters and both will be applied. Defining different schema names \u00b6 In some architectures, you might end up in a situation, where your unit tests exist in a different schema than the tested code. This is not the default or recommended approach but is supporter by utPLSQL. In such scenarios, you would probably have a separate database schema to hold unit tests and a separate schema/schemes to hold the tested code. Since by default, coverage reporting is done on the schema/schemes that the invoked tests are on, the code will not be included in coverage report as it is in a different schema than the invoked tests. In this situation you need to provide list of schema names that the tested code is in. This option overrides the default schema names for coverage. Example: exec ut . run ( 'ut3_user.test_award_bonus' , ut_coverage_html_reporter (), a_coverage_schemes => ut_varchar2_list ( 'usr' )); Executes test test_award_bonus in schema ut3_user and gather coverage for that execution on all non unit-test objects from schema usr . You can combine schema names with include/exclude parameters and all will be applied. The a_coverage_schemes parameter takes precedence however, so if include list contains objects from other schemes, that will not be considered. Example: begin ut . run ( 'ut3_user.test_award_bonus' , ut_coverage_html_reporter (), a_coverage_schemes => ut_varchar2_list ( 'usr' ), a_exclude_objects => ut_varchar2_list ( 'usr.betwnstr' ), a_include_objects => ut_varchar2_list ( 'usr.award_bonus' ) ); end ; Executes test test_award_bonus in schema ut3_user and gather coverage for that execution on award_bonus object from schema usr . The exclude list is of no relevance as it is not overlapping with include list. Working with projects and project files \u00b6 Both sonar and coveralls are utilities that are more project-oriented than database-centric. They report statistics and coverage for project files in version control system. Nowadays, most of database projects are moving away from database-centric approach towards project/product-centric approach. Coverage reporting of utPLSQL allows you to perform code coverage analysis for your project files. This feature is supported by all build-in coverage reporting formats. When using this invocation syntax, coverage is only reported for the provided files, so using project files as input for coverage is also a way of limiting the scope of coverage analysis. This syntax also allows usage of a_include_object_list and a_exclude_object_list as optional parameters to filter the scope of analysis. Reporting using externally provided file mapping One of ways to perform coverage reporting on your project files is to provide to the coverage reporter a list of file path/names along with mapping to corresponding object name and object type. Example: begin ut . run ( 'usr' , ut_coverage_html_reporter (), a_source_file_mappings => ut_file_mappings ( ut_file_mapping ( file_name => 'sources/hr/award_bonus.prc' , object_owner => 'USR' , object_name => 'AWARD_BONUS' , object_type => 'PROCEDURE' ), ut_file_mapping ( file_name => 'sources/hr/betwnstr.fnc' , object_owner => 'USR' , object_name => 'BETWNSTR' , object_type => 'FUNCTION' ) ) ); end ; Executes all tests in schema usr and reports coverage for that execution on procedure award_bonus and function betwnstr . The coverage report is mapped-back to file-system object names with paths. Reporting using regex file mapping rule If file names and paths in your project follow a well established naming conventions, then you can use the predefined rule for mapping file names to object names or you can define your own rule and pass it to the coverage reporter at runtime. Example of running with predefined regex mapping rule. begin ut . run ( 'usr' , ut_coverage_html_reporter (), a_source_files => ut_varchar2_list ( 'sources/hr/award_bonus.prc' , 'sources/hr/betwnstr.fnc' ) ); end ; The predefined rule is based on the following default values for parameters: * a_regex_pattern => '.*(\\\\|\\/)((\\w+)\\.)?(\\w+)\\.(\\w{3})' * a_object_owner_subexpression => 3 * a_object_name_subexpression => 4 * a_object_type_subexpression => 5 * a_file_to_object_type_mapping - defined in table below The predefined file extension to object type mappings file extension object type tpb type body pkb package body bdy package body trg trigger fnc function prc procedure Since package specification and type specifications are not considered by coverage, the file extensions for those objects are not included in the mapping. Examples of filename paths that will be mapped correctly using predefined rules. * [...]directory[/subdirectory[/...]]/object_name.(tpb|pkb|trg|fnc|prc) * [...]directory[/subdirectory[/...]]/schema_name.object_name.(tpb|pkb|trg|fnc|prc) * [...]directory[\\subdirectory[\\...]]\\object_name.(tpb|pkb|trg|fnc|prc) * [...]directory[\\subdirectory[\\...]]\\schema_name.object_name.(tpb|pkb|trg|fnc|prc) If file names in your project structure are not prefixed with schema name (like above), the coverage report will look for objects to match the file names in the current schema of the connection that was used to execute tests with coverage. If your project structure is different, you may define your own mapping rule using regex. Example: begin ut . run ( 'usr' , ut_coverage_html_reporter (), ut_file_mapper . build_file_mappings ( a_file_paths => ut_varchar2_list ( 'sources/hr/procedures/award_bonus.sql' , 'sources/hr/functions/betwnstr.sql' ), a_regex_pattern => '.*(\\\\|\\/)(\\w+)\\.(\\w+)\\.(\\w{3})' , a_object_owner_subexpression => 2 , a_object_type_subexpression => 3 , a_object_name_subexpression => 4 , a_file_to_object_type_mapping => ut_key_value_pairs ( ut_key_value_pair ( 'functions' , 'function' ), ut_key_value_pair ( 'procedures' , 'procedure' ) ) ) ); end ;","title":"Code coverage"},{"location":"userguide/coverage.html#coverage","text":"utPLSQL comes with build-in coverage reporting engine. The code coverage reporting is based off DBMS_PROFILER package. Code coverage is gathered for the following source types: * package bodies * type bodies * triggers * stored procedures * stored functions Note: The package specifications and type specifications are explicitly excluded from code coverage analysis.This limitation is introduced to avoid false-negatives. Most of the package specifications don't contain executable code. The only exception is initialization of global constants and variables in package specification.Since, most of package specifications are not executable at all, there is no information available on the number of lines covered and those would eb reported as 0% covered, which is not desired. To obtain information about code coverage of your Unit Tests, all you need to do is run your unit tests with one of build-in code coverage reporters. Following code coverage reporters are supplied with utPLSQL: * ut_coverage_html_reporter - generates a HTML coverage report providing summary and detailed information on code coverage. The html reporter is based on open-source simplecov-html reporter for Ruby. It includes source code of the code that was covered (if possible) * ut_coveralls_reporter - generates a Coveralls compatible JSON coverage report providing detailed information on code coverage with line numbers. This coverage report is designed to be consumed by cloud services like coveralls * ut_coverage_sonar_reporter - generates a Sonar Compatible XML coverage report providing detailed information on code coverage with line numbers. This coverage report is designed to be consumed by services like sonarqube/sonarcloud","title":"Coverage"},{"location":"userguide/coverage.html#security-model","text":"Code coverage is using DBMS_PROFILER to gather information about execution of code under test and therefore follows the DBMS_PROFILER's Security Model In order to be able to gather coverage information, user executing unit tests needs to be either: * Owner of the code that is tested * Have the following privileges to be able to gather coverage on code owned by other users: * create any procedure system privilege * execute privilege on the code that is tested (not only the unit tests) or execute any procedure system privilege If you have execute privilege on the code that are tested, but do not have create any procedure system privilege, the code that is tested will be reported as not covered (coverage = 0%). If you have execute privilege only on the unit tests, but do not have execute privilege on the code that is tested, the code will not be reported by coverage - as if it did not exist in the database. If the code that is testes is complied as NATIVE, the code coverage will not be reported as well.","title":"Security model"},{"location":"userguide/coverage.html#running-unite-tests-with-coverage","text":"Using code coverage functionality is as easy as using any other reporter for utPLSQL project. All you need to do is run your tests from your preferred SQL tool and save the outcomes of reporter to a file. All you need to do, is pass the constructor of the reporter to your ut.run Example: begin ut . run ( ut_coverage_html_reporter ()); end ; / Executes all unit tests in current schema, gather information about code coverage and output the html text into DBMS_OUTPUT. The ut_coverage_html_reporter will produce a interactive HTML report. You may see a sample of code coverage for utPLSQL project here The report provides a summary information with list of source code that was expected to be covered. The report allow to navigate to every source and inspect line by line coverage.","title":"Running unite tests with coverage"},{"location":"userguide/coverage.html#coverage-reporting-options","text":"By default the database schema/schemes containing the tests that were executed during the run, are fully reported by coverage reporter. All valid unit tests are excluded from the report regardless if they were invoked or not. This way the coverage report is not affected by presence of tests and contains only the tested code. The default behavior of coverage reporters can be altered, depending on your needs.","title":"Coverage reporting options"},{"location":"userguide/coverage.html#includingexcluding-objects-in-coverage-reports","text":"The most basic options are the include/exclude objects lists. You may specify both include and exclude objects lists to specify which objects are to be included in the report and which are to be excluded. Both of those options are meant to be used to narrow down the scope of unit test runs, that is broad by default. Example: exec ut . run ( 'ut3_user.test_award_bonus' , ut_coverage_html_reporter (), a_include_objects => ut_varchar2_list ( 'ut3_user.award_bonus' )); Executes test test_award_bonus and gather coverage only on object ut3_user.award_bonus Alternatively you could run: exec ut . run ( 'ut3_user.test_award_bonus' , ut_coverage_html_reporter (), a_exclude_objects => ut_varchar2_list ( 'ut3_user.betwnstr' )); Executes test test_award_bonus and gather on all objects in schema ut3_user except valid unit test objects and object betwnstr that schema. You can also combine the parameters and both will be applied.","title":"Including/excluding objects in coverage reports"},{"location":"userguide/coverage.html#defining-different-schema-names","text":"In some architectures, you might end up in a situation, where your unit tests exist in a different schema than the tested code. This is not the default or recommended approach but is supporter by utPLSQL. In such scenarios, you would probably have a separate database schema to hold unit tests and a separate schema/schemes to hold the tested code. Since by default, coverage reporting is done on the schema/schemes that the invoked tests are on, the code will not be included in coverage report as it is in a different schema than the invoked tests. In this situation you need to provide list of schema names that the tested code is in. This option overrides the default schema names for coverage. Example: exec ut . run ( 'ut3_user.test_award_bonus' , ut_coverage_html_reporter (), a_coverage_schemes => ut_varchar2_list ( 'usr' )); Executes test test_award_bonus in schema ut3_user and gather coverage for that execution on all non unit-test objects from schema usr . You can combine schema names with include/exclude parameters and all will be applied. The a_coverage_schemes parameter takes precedence however, so if include list contains objects from other schemes, that will not be considered. Example: begin ut . run ( 'ut3_user.test_award_bonus' , ut_coverage_html_reporter (), a_coverage_schemes => ut_varchar2_list ( 'usr' ), a_exclude_objects => ut_varchar2_list ( 'usr.betwnstr' ), a_include_objects => ut_varchar2_list ( 'usr.award_bonus' ) ); end ; Executes test test_award_bonus in schema ut3_user and gather coverage for that execution on award_bonus object from schema usr . The exclude list is of no relevance as it is not overlapping with include list.","title":"Defining different schema names"},{"location":"userguide/coverage.html#working-with-projects-and-project-files","text":"Both sonar and coveralls are utilities that are more project-oriented than database-centric. They report statistics and coverage for project files in version control system. Nowadays, most of database projects are moving away from database-centric approach towards project/product-centric approach. Coverage reporting of utPLSQL allows you to perform code coverage analysis for your project files. This feature is supported by all build-in coverage reporting formats. When using this invocation syntax, coverage is only reported for the provided files, so using project files as input for coverage is also a way of limiting the scope of coverage analysis. This syntax also allows usage of a_include_object_list and a_exclude_object_list as optional parameters to filter the scope of analysis. Reporting using externally provided file mapping One of ways to perform coverage reporting on your project files is to provide to the coverage reporter a list of file path/names along with mapping to corresponding object name and object type. Example: begin ut . run ( 'usr' , ut_coverage_html_reporter (), a_source_file_mappings => ut_file_mappings ( ut_file_mapping ( file_name => 'sources/hr/award_bonus.prc' , object_owner => 'USR' , object_name => 'AWARD_BONUS' , object_type => 'PROCEDURE' ), ut_file_mapping ( file_name => 'sources/hr/betwnstr.fnc' , object_owner => 'USR' , object_name => 'BETWNSTR' , object_type => 'FUNCTION' ) ) ); end ; Executes all tests in schema usr and reports coverage for that execution on procedure award_bonus and function betwnstr . The coverage report is mapped-back to file-system object names with paths. Reporting using regex file mapping rule If file names and paths in your project follow a well established naming conventions, then you can use the predefined rule for mapping file names to object names or you can define your own rule and pass it to the coverage reporter at runtime. Example of running with predefined regex mapping rule. begin ut . run ( 'usr' , ut_coverage_html_reporter (), a_source_files => ut_varchar2_list ( 'sources/hr/award_bonus.prc' , 'sources/hr/betwnstr.fnc' ) ); end ; The predefined rule is based on the following default values for parameters: * a_regex_pattern => '.*(\\\\|\\/)((\\w+)\\.)?(\\w+)\\.(\\w{3})' * a_object_owner_subexpression => 3 * a_object_name_subexpression => 4 * a_object_type_subexpression => 5 * a_file_to_object_type_mapping - defined in table below The predefined file extension to object type mappings file extension object type tpb type body pkb package body bdy package body trg trigger fnc function prc procedure Since package specification and type specifications are not considered by coverage, the file extensions for those objects are not included in the mapping. Examples of filename paths that will be mapped correctly using predefined rules. * [...]directory[/subdirectory[/...]]/object_name.(tpb|pkb|trg|fnc|prc) * [...]directory[/subdirectory[/...]]/schema_name.object_name.(tpb|pkb|trg|fnc|prc) * [...]directory[\\subdirectory[\\...]]\\object_name.(tpb|pkb|trg|fnc|prc) * [...]directory[\\subdirectory[\\...]]\\schema_name.object_name.(tpb|pkb|trg|fnc|prc) If file names in your project structure are not prefixed with schema name (like above), the coverage report will look for objects to match the file names in the current schema of the connection that was used to execute tests with coverage. If your project structure is different, you may define your own mapping rule using regex. Example: begin ut . run ( 'usr' , ut_coverage_html_reporter (), ut_file_mapper . build_file_mappings ( a_file_paths => ut_varchar2_list ( 'sources/hr/procedures/award_bonus.sql' , 'sources/hr/functions/betwnstr.sql' ), a_regex_pattern => '.*(\\\\|\\/)(\\w+)\\.(\\w+)\\.(\\w{3})' , a_object_owner_subexpression => 2 , a_object_type_subexpression => 3 , a_object_name_subexpression => 4 , a_file_to_object_type_mapping => ut_key_value_pairs ( ut_key_value_pair ( 'functions' , 'function' ), ut_key_value_pair ( 'procedures' , 'procedure' ) ) ) ); end ;","title":"Working with projects and project files"},{"location":"userguide/exception-reporting.html","text":"Exception handling and reporting \u00b6 The utPLSQL is responsible for handling exceptions wherever they occur in the test run. utPLSQL is trapping most of the exceptions so that the test execution is not affected by individual tests or test packages throwing an exception. The framework provides a full stacktrace for every exception that was thrown. The stacktrace is clean and does not include any utPLSQL library calls in it. To achieve rerunability, the ORA-04068, ORA-04061 exceptions are not handled and test execution will be interrupted if such exception is encountered. This is because of how Oracle behaves on those exceptions. Test execution can fail for different reasons. The failures on different exceptions are handled as follows: * A test package without body - each %test is reported as failed with exception, nothing is executed * A test package with invalid body - each %test is reported as failed with exception, nothing is executed * A test package with invalid spec - package is not considered a valid unit test package and is excluded from execution. When trying to run a test package with invalid spec explicitly, exception is raised. Only valid specifications are parsed for annotations * A test package that is raising an exception in %beforeall - each %test is reported as failed with exception, %test , %beforeeach , %beforetest , %aftertest and %aftereach are not executed. %afterall is executed to allow cleanup of whatever was done in %beforeall * A test package that is raising an exception in %beforeeach - each %test is reported as failed with exception, %test , %beforetest and %aftertest is not executed. The %aftereach and %afterall blocks are getting executed to allow cleanup of whatever was done in %before... blocks * A test package that is raising an exception in %beforetest - the %test is reported as failed with exception, %test is not executed. The %aftertest , %aftereach and %afterall blocks are getting executed to allow cleanup of whatever was done in %before... blocks * A test package that is raising an exception in %test - the %test is reported as failed with exception. The execution of other blocks continues normally * A test package that is raising an exception in %aftertest - the %test is reported as failed with exception. The execution of other blocks continues normally * A test package that is raising an exception in %aftereach - each %test is reported as failed with exception. * A test package that is raising an exception in %afterall - all blocks of the package are executed, as the %afterall is the last step of package execution. Exception in %afterall is not affecting test results. A warning with exception stacktrace is displayed in the summary Example of reporting with exception thrown in %beforetest : Remove rooms by name Removes a room without content in it (FAILED - 1) Does not remove room when it has content Raises exception when null room name given Failures: 1) remove_empty_room error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 39 ORA-06512: at line 6 Finished in ,039346 seconds 3 tests, 0 failed, 1 errored, 0 ignored. Example of reporting with exception thrown in %test : Remove rooms by name Removes a room without content in it (FAILED - 1) Does not remove room when it has content Raises exception when null room name given Failures: 1) remove_empty_room error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 48 ORA-06512: at line 6 Finished in ,035726 seconds 3 tests, 0 failed, 1 errored, 0 ignored. Example of reporting with exception thrown in %aftertest : Remove rooms by name Removes a room without content in it (FAILED - 1) Does not remove room when it has content Raises exception when null room name given Failures: 1) remove_empty_room error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 42 ORA-06512: at line 6 Finished in ,045523 seconds 3 tests, 0 failed, 1 errored, 0 ignored. Example of reporting with exception thrown in %aftereach : Remove rooms by name Removes a room without content in it (FAILED - 1) Does not remove room when it has content (FAILED - 2) Raises exception when null room name given (FAILED - 3) Failures: 1) remove_empty_room error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 31 ORA-06512: at line 6 2) room_with_content error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 31 ORA-06512: at line 6 3) null_room_name error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 31 ORA-06512: at line 6 Finished in ,034863 seconds 3 tests, 0 failed, 3 errored, 0 ignored. Example of reporting with exception thrown in %afterall : Remove rooms by name Removes a room without content in it Does not remove room when it has content Raises exception when null room name given Warnings: 1) test_remove_rooms_by_name - Afterall procedure failed: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 35 ORA-06512: at line 6 Finished in ,044902 seconds 3 tests, 0 failed, 0 errored, 0 ignored. 1 warning(s)","title":"Error handling and reporting"},{"location":"userguide/exception-reporting.html#exception-handling-and-reporting","text":"The utPLSQL is responsible for handling exceptions wherever they occur in the test run. utPLSQL is trapping most of the exceptions so that the test execution is not affected by individual tests or test packages throwing an exception. The framework provides a full stacktrace for every exception that was thrown. The stacktrace is clean and does not include any utPLSQL library calls in it. To achieve rerunability, the ORA-04068, ORA-04061 exceptions are not handled and test execution will be interrupted if such exception is encountered. This is because of how Oracle behaves on those exceptions. Test execution can fail for different reasons. The failures on different exceptions are handled as follows: * A test package without body - each %test is reported as failed with exception, nothing is executed * A test package with invalid body - each %test is reported as failed with exception, nothing is executed * A test package with invalid spec - package is not considered a valid unit test package and is excluded from execution. When trying to run a test package with invalid spec explicitly, exception is raised. Only valid specifications are parsed for annotations * A test package that is raising an exception in %beforeall - each %test is reported as failed with exception, %test , %beforeeach , %beforetest , %aftertest and %aftereach are not executed. %afterall is executed to allow cleanup of whatever was done in %beforeall * A test package that is raising an exception in %beforeeach - each %test is reported as failed with exception, %test , %beforetest and %aftertest is not executed. The %aftereach and %afterall blocks are getting executed to allow cleanup of whatever was done in %before... blocks * A test package that is raising an exception in %beforetest - the %test is reported as failed with exception, %test is not executed. The %aftertest , %aftereach and %afterall blocks are getting executed to allow cleanup of whatever was done in %before... blocks * A test package that is raising an exception in %test - the %test is reported as failed with exception. The execution of other blocks continues normally * A test package that is raising an exception in %aftertest - the %test is reported as failed with exception. The execution of other blocks continues normally * A test package that is raising an exception in %aftereach - each %test is reported as failed with exception. * A test package that is raising an exception in %afterall - all blocks of the package are executed, as the %afterall is the last step of package execution. Exception in %afterall is not affecting test results. A warning with exception stacktrace is displayed in the summary Example of reporting with exception thrown in %beforetest : Remove rooms by name Removes a room without content in it (FAILED - 1) Does not remove room when it has content Raises exception when null room name given Failures: 1) remove_empty_room error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 39 ORA-06512: at line 6 Finished in ,039346 seconds 3 tests, 0 failed, 1 errored, 0 ignored. Example of reporting with exception thrown in %test : Remove rooms by name Removes a room without content in it (FAILED - 1) Does not remove room when it has content Raises exception when null room name given Failures: 1) remove_empty_room error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 48 ORA-06512: at line 6 Finished in ,035726 seconds 3 tests, 0 failed, 1 errored, 0 ignored. Example of reporting with exception thrown in %aftertest : Remove rooms by name Removes a room without content in it (FAILED - 1) Does not remove room when it has content Raises exception when null room name given Failures: 1) remove_empty_room error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 42 ORA-06512: at line 6 Finished in ,045523 seconds 3 tests, 0 failed, 1 errored, 0 ignored. Example of reporting with exception thrown in %aftereach : Remove rooms by name Removes a room without content in it (FAILED - 1) Does not remove room when it has content (FAILED - 2) Raises exception when null room name given (FAILED - 3) Failures: 1) remove_empty_room error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 31 ORA-06512: at line 6 2) room_with_content error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 31 ORA-06512: at line 6 3) null_room_name error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 31 ORA-06512: at line 6 Finished in ,034863 seconds 3 tests, 0 failed, 3 errored, 0 ignored. Example of reporting with exception thrown in %afterall : Remove rooms by name Removes a room without content in it Does not remove room when it has content Raises exception when null room name given Warnings: 1) test_remove_rooms_by_name - Afterall procedure failed: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 35 ORA-06512: at line 6 Finished in ,044902 seconds 3 tests, 0 failed, 0 errored, 0 ignored. 1 warning(s)","title":"Exception handling and reporting"},{"location":"userguide/expectations.html","text":"Concepts \u00b6 Validation of the code under test (the tested logic of procedure/function etc.) is performed by comparing the actual data against the expected data. To achieve that, we use a combination of expectation and matcher to perform the check on the data. Example of a unit test procedure body. begin ut . expect ( 'the tested value' , 'optional custom failure message' ). to_ ( equal ( 'the expected value' ) ); end ; Expectation is a set of the expected value(s), actual values(s) and the matcher(s) to run on those values. You can also add a custom failure message for an expectation. Matcher defines the comparison operation to be performed on expected and actual values. Pseudo-code: ut.expect( a_actual {data-type} [, a_message {varchar2}] ).to_( {matcher} ); ut.expect( a_actual {data-type} [, a_message {varchar2}] ).not_to( {matcher} ); All matchers have shortcuts like: ut.expect( a_actual {data-type} ).to_{matcher}; ut.expect( a_actual {data-type} ).not_to_{matcher}; Providing a custom failure message \u00b6 Expectations allow you to provide a custom error message as second argument: -- Pseudocode ut . expect ( a_actual { data - type } , a_message { varchar2 } ). to_ { matcher } ; -- Example ut . expect ( 'supercat' , 'checked superhero-animal was not a dog' ). to_ ( equal ( 'superdog' ) ); The message is added to the normal failure message returned by the matcher. This is not only useful to give more detailed and specific information about a test, but also if you have some kind of dynamic tests. Dynamic tests example \u00b6 You have a bunch of tables and an archive-functionality for them and you want to test if the things you put into live-tables are removed from live-tables and present in archive-tables: procedure test_data_existance ( i_tableName varchar2 ) as v_count_real integer ; v_count_archive integer ; begin execute immediate 'select count(*) from ' || i_tablename || '' into v_count_real ; execute immediate 'select count(*) from ' || i_tablename || '_archive' into v_count_archive ; ut . expect ( v_count_archive , 'failure checking entry-count of ' || i_tablename || '_archive' ). to_ ( equal ( 1 ) ); ut . expect ( v_count_real , 'failure checking entry-count of ' || i_tablename ). to_ ( equal ( 0 ) ); end ; procedure test_archive_data as begin -- Arrange -- insert several data into real-tables here -- Act package_to_test . archive_data (); -- Assert test_data_existance ( 'TABLE_A' ); test_data_existance ( 'TABLE_B' ); test_data_existance ( 'TABLE_C' ); test_data_existance ( 'TABLE_D' ); end ; A failed output will look like this: Failures: 1) test_archive_data \"failure checking entry-count of TABLE_A_archive\" Actual: 2 (number) was expected to equal: 1 (number) at \"UT_TEST_PACKAGE.TEST_DATA_EXISTANCE\", line 12 ut.expect( v_count_archive, 'failure checking entry-count of ' || i_tablename || '_archive' ).to_( equal(1) ); Matchers \u00b6 utPLSQL provides the following matchers to perform checks on the expected and actual values. be_between be_empty be_false be_greater_than be_greater_or_equal be_less_or_equal be_less_than be_like be_not_null be_null be_true equal match be_between \u00b6 Validates that the actual value is between the lower and upper bound. Example: begin ut . expect ( a_actual => 3 ). to_be_between ( a_lower_bound => 1 , a_upper_bound => 3 ); ut . expect ( 3 ). to_be_between ( 1 , 3 ); --or ut . expect ( a_actual => 3 ). to_ ( be_between ( a_lower_bound => 1 , a_upper_bound => 3 ) ); ut . expect ( 3 ). to_ ( be_between ( 1 , 3 ) ); end ; be_empty \u00b6 Unary matcher that validates if the provided dataset is empty. Usage: procedure test_if_cursor_is_empty is l_cursor sys_refcursor ; begin open l_cursor for select * from dual where 1 = 0 ; ut . expect ( l_cursor ). to_be_empty (); --or ut . expect ( l_cursor ). to_ ( be_empty () ); end ; When used with anydata, it is only valid for collection data types. be_false \u00b6 Unary matcher that validates if the provided value is false. Usage: begin ut . expect ( ( 1 = 0 ) ). to_be_false (); --or ut . expect ( ( 1 = 0 ) ). to_ ( be_false () ); end ; be_greater_or_equal \u00b6 Checks if the actual value is greater or equal than the expected. Usage: begin ut . expect ( sysdate ). to_be_greater_or_equal ( sysdate - 1 ); --or ut . expect ( sysdate ). to_ ( be_greater_or_equal ( sysdate - 1 ) ); end ; be_greater_than \u00b6 Checks if the actual value is greater than the expected. Usage: begin ut . expect ( 2 ). to_be_greater_than ( 1 ); --or ut . expect ( 2 ). to_ ( be_greater_than ( 1 ) ); end ; be_less_or_equal \u00b6 Checks if the actual value is less or equal than the expected. Usage: begin ut . expect ( 3 ). to_be_less_or_equal ( 3 ); --or ut . expect ( 3 ). to_ ( be_less_or_equal ( 3 ) ); end ; be_less_than \u00b6 Checks if the actual value is less than the expected. Usage: begin ut . expect ( 3 ). to_be_less_than ( 2 ); --or ut . expect ( 3 ). to_ ( be_less_than ( 2 ) ); end ; be_like \u00b6 Validates that the actual value is like the expected expression. Usage: begin ut . expect ( 'Lorem_impsum' ). to_be_like ( a_mask => '%rem#_%' , a_escape_char => '#' ); ut . expect ( 'Lorem_impsum' ). to_be_like ( '%rem#_%' , '#' ); --or ut . expect ( 'Lorem_impsum' ). to_ ( be_like ( a_mask => '%rem#_%' , a_escape_char => '#' ) ); ut . expect ( 'Lorem_impsum' ). to_ ( be_like ( '%rem#_%' , '#' ) ); end ; Parameters a_mask and a_escape_char represent valid parameters of the Oracle LIKE condition be_not_null \u00b6 Unary matcher that validates if the actual value is not null. Usage: begin ut . expect ( to_clob ( 'ABC' ) ). to_be_not_null (); --or ut . expect ( to_clob ( 'ABC' ) ). to_ ( be_not_null () ); --or ut . expect ( to_clob ( 'ABC' ) ). not_to ( be_null () ); end ; be_null \u00b6 Unary matcher that validates if the actual value is null. Usage: begin ut . expect ( cast ( null as varchar2 ( 100 )) ). to_be_null (); --or ut . expect ( cast ( null as varchar2 ( 100 )) ). to_ ( be_null () ); end ; be_true \u00b6 Unary matcher that validates if the provided value is true. - boolean Usage: begin ut . expect ( ( 1 = 1 ) ). to_be_true (); --or ut . expect ( ( 1 = 1 ) ). to_ ( be_true () ); end ; match \u00b6 Validates that the actual value is matching the expected regular expression. Usage: begin ut . expect ( a_actual => '123-456-ABcd' ). to_match ( a_pattern => '\\d{3}-\\d{3}-[a-z]' , a_modifiers => 'i' ); ut . expect ( 'some value' ). to_match ( '^some.*' ); --or ut . expect ( a_actual => '123-456-ABcd' ). to_ ( match ( a_pattern => '\\d{3}-\\d{3}-[a-z]' , a_modifiers => 'i' ) ); ut . expect ( 'some value' ). to_ ( match ( '^some.*' ) ); end ; Parameters a_pattern and a_modifiers represent a valid regexp pattern accepted by Oracle REGEXP_LIKE condition equal \u00b6 The equal matcher is a very restrictive matcher. It only returns true if the compared data-types are the same. That means that comparing varchar2 to a number will fail even if the varchar2 contains the same number. This matcher is designed to capture changes of data-type, so that if you expect your variable to be a number and it is now some other type, the test will fail and give you early indication of a potential problem. Usage: declare x varchar2 ( 100 ); y varchar2 ( 100 ); begin ut . expect ( 'a dog' ). to_equal ( 'a dog' ); ut . expect ( a_actual => y ). to_equal ( a_expected => x , a_nulls_are_equal => true ); --or ut . expect ( 'a dog' ). to_ ( equal ( 'a dog' ) ); ut . expect ( a_actual => y ). to_ ( equal ( a_expected => x , a_nulls_are_equal => true ) ); end ; The a_nulls_are_equal parameter controls the behavior of a null=null comparison ( this comparison by default is true! ) Excluding columns and attributes from comparison \u00b6 The equal matcher accepts an additional parameter a_exclude when used to compare data of cursor , object or table type . This parameter can take three forms: 1. A varchar2 containing comma separated names of columns/attributes to exclude 2. A varchar2 containing XPath expression that lists items to be excluded 3. A ut_varchar2_list containing list of columns/attributes to exclude The column/attribute names are case sensitive and cannot be quoted. If the a_exclude parameter is not specified, whole cursor/object/table type is compared. If a column/attribute to be excluded does not exist it is simply ignored (no error). This is useful when testing elements data that cannot be determined or set up by the tests (like sysdate populated by default on audit columns). procedure test_cursors_skip_columns is l_expected sys_refcursor ; l_actual sys_refcursor ; begin open l_expected for select 'text' ignore_me , d . * from user_tables d ; open l_actual for select sysdate \"ADate\" , d . * from user_tables d ; ut . expect ( l_actual ). to_equal ( l_expected , a_exclude => 'IGNORE_ME,ADate' ); end ; create or replace type employee as object ( first_name varchar2 ( 50 ), last_name varchar2 ( 50 ), hire_date date , created_at timestamp , created_by varchar2 ( 30 ), modified_at timestamp , modified_by varchar2 ( 50 ) ); procedure test_object_skip_columns is l_expected employee ; l_actual employee ; begin l_expected : = employee ( 'John' || rownum , 'Doe' , sysdate , systimestamp , 'me' , systimestamp , 'me' ); -- the actual should normally be returned by the tested code. l_actual : = employee ( 'John' || rownum , 'Doe' , sysdate , systimestamp , 'me' , systimestamp , 'me' ); -- test the data excluding attributes specified by XPath ut . expect ( anydata . convertObject ( l_actual ) ). to_equal ( anydata . convertObject ( l_expected ), a_exclude => '/EMPLOYEE/CREATED_AT|/EMPLOYEE/MODIFIED_AT' ); end ; Using cursors to compare PLSQL records on Oracle 12c \u00b6 There is a great article by Tim Hall on using the TABLE Operator with Locally Defined Types in PL/SQL . If you are on Oracle 12c, you can benefit from this feature to make comparison of PLSQL records and tables super-simple in utPLSQL. You can use the feature described in the article to convert PLSQL records and collection types to cursors. Complex cursor data can then be compared in utPLQL. Comparing cursor data containing DATE fields \u00b6 Important note utPLSQL uses XMLType internally to represent rows of the cursor data. This is by far the most flexible method and allows comparison of cursors containing LONG, CLOB, BLOB, user defined types and even nested cursors. Due to the way Oracle handles DATE data type when converting from cursor data to XML, utPLSQL has no control over the DATE formatting. The NLS_DATE_FORMAT setting from the moment the cursor was opened determines the formatting of dates used for cursor data comparison. By default, Oracle NLS_DATE_FORMAT is timeless, so data of DATE datatype, will be compared ignoring the time component. You should use procedures ut.set_nls , ut.reset_nls around cursors that you want to compare in your tests. This way, the DATE data in cursors will be properly formatted for comparison using date-time format. The example below makes use of ut.set_nls , ut.reset_nls , so that the date in l_expected and l_actual is compared using date-time formatting. create table events ( description varchar2 ( 4000 ), event_date date ); create or replace function get_events ( a_date_from date , a_date_to date ) return sys_refcursor is l_result sys_refcursor ; begin open l_result for select description , event_date from events where event_date between a_date_from and a_date_to ; return l_result ; end ; / create or replace package test_get_events is --%suite(get_events) --%beforeall procedure setup_events ; --%test(returns event within date range) procedure get_events_for_date_range ; end ; / create or replace package body test_get_events is gc_description constant varchar2 ( 30 ) : = 'Test event' ; gc_event_date constant date : = to_date ( '2016-09-08 06:51:22' , 'yyyy-mm-dd hh24:mi:ss' ); procedure setup_events is begin insert into events ( description , event_date ) values ( gc_description , gc_event_date ); end ; procedure get_events_for_date_range is l_expected sys_refcursor ; l_actual sys_refcursor ; l_expected_bad_date sys_refcursor ; l_second number : = 1 / 24 / 60 / 60 ; begin ut . set_nls (); open l_expected for select gc_description as description , gc_event_date as event_date from dual ; open l_expected_bad_date for select gc_description as description , gc_event_date + l_second as event_date from dual ; l_actual : = get_events ( gc_event_date - 1 , gc_event_date + 1 ); ut . reset_nls (); ut . expect ( l_actual ). to_equal ( l_expected ); ut . expect ( l_actual ). not_to_equal ( l_expected_bad_date ); end ; end ; / begin ut . run (); end ; / drop table events ; drop function get_events ; drop package test_get_events ; Comparing user defined types and collections \u00b6 The anydata data type is used to compare user defined objects and collections. Example: create type department as object ( name varchar2 ( 30 )); / create type departments as table of department ; / create or replace package demo_dept as -- %suite(demo) --%test(demo of object to object comparison) procedure test_department ; --%test(demo of collection comparison) procedure test_departments ; end ; / create or replace package body demo_dept as procedure test_department is v_expected department ; v_actual department ; begin v_expected : = department ( 'HR' ); v_actual : = department ( 'IT' ); ut . expect ( anydata . convertObject ( v_expected ) ). to_equal ( anydata . convertObject ( v_actual ) ); end ; procedure test_department is v_expected department ; v_actual department ; begin v_expected : = departments ( department ( 'HR' )); v_actual : = departments ( department ( 'IT' )); ut . expect ( anydata . convertCollection ( v_expected ) ). to_equal ( anydata . convertCollection ( v_actual ) ); end ; end ; / This test will fail as v_actual is not equal v_expected . Expecting exceptions \u00b6 Below example illustrates how to write test to check for expected exceptions (thrown by tested code). create or replace procedure divide ( p_a number , p_b number ) is begin return p_a / p_b ; end ; / create or replace package test_divide is --%suite(Divide functionality) --%test(Raises exception when divisor is zero) procedure divide_raises_zero_divisor ; end ; / create or replace package body test_divide is procedure divide_raises_zero_divisor is l_my_number number ; begin l_my_number : = divide ( 1 , 0 ); -- PLSQL call throwing ORA-01476 exception ut . fail ( 'Expected exception but nothing was raised' ); exception when others then ut . expect ( sqlcode ). to_equal ( - 1476 ); ut . expect ( sqlerrm ). to_match ( 'equal to zero' ); end ; end ; / The call to ut.fail is required to make sure that the test fails, if we expect an exception, but the tested code does not throw any. The call to ut.expect uses equal matcher to check that the exception that was raised was exactly the one we were expecting to get in particular situation. Depending on the situation you will want to check for sqlcode , sqlerrm , both or perform additional expectation checks to make sure nothing was changed by the called procedure in the database. Supported data types \u00b6 The matrix below illustrates the data types supported by different matchers. be_between be_empty be_false be_greater_than be_greater_or_equal be_less_or_equal be_less_than be_like be_not_null be_null be_true equal match anydata X X X X blob X X X boolean X X X X X clob X X X X X date X X X X X X X X number X X X X X X X X refcursor X X X X timestamp X X X X X X X X timestamp with timezone X X X X X X X X timestamp with local timezone X X X X X X X X varchar2 X X X X X X interval year to month X X X X X X X X interval day to second X X X X X X X X Negating a matcher \u00b6 Expectations provide a very convenient way to perform a check on a negated matcher. Syntax to check for matcher evaluating to true: begin ut . expect ( a_actual { data - type } ). to_ { matcher } ; ut . expect ( a_actual { data - type } ). to_ ( { matcher } ); end ; Syntax to check for matcher evaluating to false: begin ut . expect ( a_actual { data - type } ). not_to_ { matcher } ; ut . expect ( a_actual { data - type } ). not_to ( { matcher } ); end ; If a matcher evaluated to NULL, then both to_ and not_to will cause the expectation to report failure. Example: begin ut . expect ( null ). to_ ( be_true () ); ut . expect ( null ). not_to ( be_true () ); end ; Since NULL is neither true nor not true , both expectations will report failure.","title":"Expectations"},{"location":"userguide/expectations.html#concepts","text":"Validation of the code under test (the tested logic of procedure/function etc.) is performed by comparing the actual data against the expected data. To achieve that, we use a combination of expectation and matcher to perform the check on the data. Example of a unit test procedure body. begin ut . expect ( 'the tested value' , 'optional custom failure message' ). to_ ( equal ( 'the expected value' ) ); end ; Expectation is a set of the expected value(s), actual values(s) and the matcher(s) to run on those values. You can also add a custom failure message for an expectation. Matcher defines the comparison operation to be performed on expected and actual values. Pseudo-code: ut.expect( a_actual {data-type} [, a_message {varchar2}] ).to_( {matcher} ); ut.expect( a_actual {data-type} [, a_message {varchar2}] ).not_to( {matcher} ); All matchers have shortcuts like: ut.expect( a_actual {data-type} ).to_{matcher}; ut.expect( a_actual {data-type} ).not_to_{matcher};","title":"Concepts"},{"location":"userguide/expectations.html#providing-a-custom-failure-message","text":"Expectations allow you to provide a custom error message as second argument: -- Pseudocode ut . expect ( a_actual { data - type } , a_message { varchar2 } ). to_ { matcher } ; -- Example ut . expect ( 'supercat' , 'checked superhero-animal was not a dog' ). to_ ( equal ( 'superdog' ) ); The message is added to the normal failure message returned by the matcher. This is not only useful to give more detailed and specific information about a test, but also if you have some kind of dynamic tests.","title":"Providing a custom failure message"},{"location":"userguide/expectations.html#dynamic-tests-example","text":"You have a bunch of tables and an archive-functionality for them and you want to test if the things you put into live-tables are removed from live-tables and present in archive-tables: procedure test_data_existance ( i_tableName varchar2 ) as v_count_real integer ; v_count_archive integer ; begin execute immediate 'select count(*) from ' || i_tablename || '' into v_count_real ; execute immediate 'select count(*) from ' || i_tablename || '_archive' into v_count_archive ; ut . expect ( v_count_archive , 'failure checking entry-count of ' || i_tablename || '_archive' ). to_ ( equal ( 1 ) ); ut . expect ( v_count_real , 'failure checking entry-count of ' || i_tablename ). to_ ( equal ( 0 ) ); end ; procedure test_archive_data as begin -- Arrange -- insert several data into real-tables here -- Act package_to_test . archive_data (); -- Assert test_data_existance ( 'TABLE_A' ); test_data_existance ( 'TABLE_B' ); test_data_existance ( 'TABLE_C' ); test_data_existance ( 'TABLE_D' ); end ; A failed output will look like this: Failures: 1) test_archive_data \"failure checking entry-count of TABLE_A_archive\" Actual: 2 (number) was expected to equal: 1 (number) at \"UT_TEST_PACKAGE.TEST_DATA_EXISTANCE\", line 12 ut.expect( v_count_archive, 'failure checking entry-count of ' || i_tablename || '_archive' ).to_( equal(1) );","title":"Dynamic tests example"},{"location":"userguide/expectations.html#matchers","text":"utPLSQL provides the following matchers to perform checks on the expected and actual values. be_between be_empty be_false be_greater_than be_greater_or_equal be_less_or_equal be_less_than be_like be_not_null be_null be_true equal match","title":"Matchers"},{"location":"userguide/expectations.html#be_between","text":"Validates that the actual value is between the lower and upper bound. Example: begin ut . expect ( a_actual => 3 ). to_be_between ( a_lower_bound => 1 , a_upper_bound => 3 ); ut . expect ( 3 ). to_be_between ( 1 , 3 ); --or ut . expect ( a_actual => 3 ). to_ ( be_between ( a_lower_bound => 1 , a_upper_bound => 3 ) ); ut . expect ( 3 ). to_ ( be_between ( 1 , 3 ) ); end ;","title":"be_between"},{"location":"userguide/expectations.html#be_empty","text":"Unary matcher that validates if the provided dataset is empty. Usage: procedure test_if_cursor_is_empty is l_cursor sys_refcursor ; begin open l_cursor for select * from dual where 1 = 0 ; ut . expect ( l_cursor ). to_be_empty (); --or ut . expect ( l_cursor ). to_ ( be_empty () ); end ; When used with anydata, it is only valid for collection data types.","title":"be_empty"},{"location":"userguide/expectations.html#be_false","text":"Unary matcher that validates if the provided value is false. Usage: begin ut . expect ( ( 1 = 0 ) ). to_be_false (); --or ut . expect ( ( 1 = 0 ) ). to_ ( be_false () ); end ;","title":"be_false"},{"location":"userguide/expectations.html#be_greater_or_equal","text":"Checks if the actual value is greater or equal than the expected. Usage: begin ut . expect ( sysdate ). to_be_greater_or_equal ( sysdate - 1 ); --or ut . expect ( sysdate ). to_ ( be_greater_or_equal ( sysdate - 1 ) ); end ;","title":"be_greater_or_equal"},{"location":"userguide/expectations.html#be_greater_than","text":"Checks if the actual value is greater than the expected. Usage: begin ut . expect ( 2 ). to_be_greater_than ( 1 ); --or ut . expect ( 2 ). to_ ( be_greater_than ( 1 ) ); end ;","title":"be_greater_than"},{"location":"userguide/expectations.html#be_less_or_equal","text":"Checks if the actual value is less or equal than the expected. Usage: begin ut . expect ( 3 ). to_be_less_or_equal ( 3 ); --or ut . expect ( 3 ). to_ ( be_less_or_equal ( 3 ) ); end ;","title":"be_less_or_equal"},{"location":"userguide/expectations.html#be_less_than","text":"Checks if the actual value is less than the expected. Usage: begin ut . expect ( 3 ). to_be_less_than ( 2 ); --or ut . expect ( 3 ). to_ ( be_less_than ( 2 ) ); end ;","title":"be_less_than"},{"location":"userguide/expectations.html#be_like","text":"Validates that the actual value is like the expected expression. Usage: begin ut . expect ( 'Lorem_impsum' ). to_be_like ( a_mask => '%rem#_%' , a_escape_char => '#' ); ut . expect ( 'Lorem_impsum' ). to_be_like ( '%rem#_%' , '#' ); --or ut . expect ( 'Lorem_impsum' ). to_ ( be_like ( a_mask => '%rem#_%' , a_escape_char => '#' ) ); ut . expect ( 'Lorem_impsum' ). to_ ( be_like ( '%rem#_%' , '#' ) ); end ; Parameters a_mask and a_escape_char represent valid parameters of the Oracle LIKE condition","title":"be_like"},{"location":"userguide/expectations.html#be_not_null","text":"Unary matcher that validates if the actual value is not null. Usage: begin ut . expect ( to_clob ( 'ABC' ) ). to_be_not_null (); --or ut . expect ( to_clob ( 'ABC' ) ). to_ ( be_not_null () ); --or ut . expect ( to_clob ( 'ABC' ) ). not_to ( be_null () ); end ;","title":"be_not_null"},{"location":"userguide/expectations.html#be_null","text":"Unary matcher that validates if the actual value is null. Usage: begin ut . expect ( cast ( null as varchar2 ( 100 )) ). to_be_null (); --or ut . expect ( cast ( null as varchar2 ( 100 )) ). to_ ( be_null () ); end ;","title":"be_null"},{"location":"userguide/expectations.html#be_true","text":"Unary matcher that validates if the provided value is true. - boolean Usage: begin ut . expect ( ( 1 = 1 ) ). to_be_true (); --or ut . expect ( ( 1 = 1 ) ). to_ ( be_true () ); end ;","title":"be_true"},{"location":"userguide/expectations.html#match","text":"Validates that the actual value is matching the expected regular expression. Usage: begin ut . expect ( a_actual => '123-456-ABcd' ). to_match ( a_pattern => '\\d{3}-\\d{3}-[a-z]' , a_modifiers => 'i' ); ut . expect ( 'some value' ). to_match ( '^some.*' ); --or ut . expect ( a_actual => '123-456-ABcd' ). to_ ( match ( a_pattern => '\\d{3}-\\d{3}-[a-z]' , a_modifiers => 'i' ) ); ut . expect ( 'some value' ). to_ ( match ( '^some.*' ) ); end ; Parameters a_pattern and a_modifiers represent a valid regexp pattern accepted by Oracle REGEXP_LIKE condition","title":"match"},{"location":"userguide/expectations.html#equal","text":"The equal matcher is a very restrictive matcher. It only returns true if the compared data-types are the same. That means that comparing varchar2 to a number will fail even if the varchar2 contains the same number. This matcher is designed to capture changes of data-type, so that if you expect your variable to be a number and it is now some other type, the test will fail and give you early indication of a potential problem. Usage: declare x varchar2 ( 100 ); y varchar2 ( 100 ); begin ut . expect ( 'a dog' ). to_equal ( 'a dog' ); ut . expect ( a_actual => y ). to_equal ( a_expected => x , a_nulls_are_equal => true ); --or ut . expect ( 'a dog' ). to_ ( equal ( 'a dog' ) ); ut . expect ( a_actual => y ). to_ ( equal ( a_expected => x , a_nulls_are_equal => true ) ); end ; The a_nulls_are_equal parameter controls the behavior of a null=null comparison ( this comparison by default is true! )","title":"equal"},{"location":"userguide/expectations.html#excluding-columns-and-attributes-from-comparison","text":"The equal matcher accepts an additional parameter a_exclude when used to compare data of cursor , object or table type . This parameter can take three forms: 1. A varchar2 containing comma separated names of columns/attributes to exclude 2. A varchar2 containing XPath expression that lists items to be excluded 3. A ut_varchar2_list containing list of columns/attributes to exclude The column/attribute names are case sensitive and cannot be quoted. If the a_exclude parameter is not specified, whole cursor/object/table type is compared. If a column/attribute to be excluded does not exist it is simply ignored (no error). This is useful when testing elements data that cannot be determined or set up by the tests (like sysdate populated by default on audit columns). procedure test_cursors_skip_columns is l_expected sys_refcursor ; l_actual sys_refcursor ; begin open l_expected for select 'text' ignore_me , d . * from user_tables d ; open l_actual for select sysdate \"ADate\" , d . * from user_tables d ; ut . expect ( l_actual ). to_equal ( l_expected , a_exclude => 'IGNORE_ME,ADate' ); end ; create or replace type employee as object ( first_name varchar2 ( 50 ), last_name varchar2 ( 50 ), hire_date date , created_at timestamp , created_by varchar2 ( 30 ), modified_at timestamp , modified_by varchar2 ( 50 ) ); procedure test_object_skip_columns is l_expected employee ; l_actual employee ; begin l_expected : = employee ( 'John' || rownum , 'Doe' , sysdate , systimestamp , 'me' , systimestamp , 'me' ); -- the actual should normally be returned by the tested code. l_actual : = employee ( 'John' || rownum , 'Doe' , sysdate , systimestamp , 'me' , systimestamp , 'me' ); -- test the data excluding attributes specified by XPath ut . expect ( anydata . convertObject ( l_actual ) ). to_equal ( anydata . convertObject ( l_expected ), a_exclude => '/EMPLOYEE/CREATED_AT|/EMPLOYEE/MODIFIED_AT' ); end ;","title":"Excluding columns and attributes from comparison"},{"location":"userguide/expectations.html#using-cursors-to-compare-plsql-records-on-oracle-12c","text":"There is a great article by Tim Hall on using the TABLE Operator with Locally Defined Types in PL/SQL . If you are on Oracle 12c, you can benefit from this feature to make comparison of PLSQL records and tables super-simple in utPLSQL. You can use the feature described in the article to convert PLSQL records and collection types to cursors. Complex cursor data can then be compared in utPLQL.","title":"Using cursors to compare PLSQL records on Oracle 12c"},{"location":"userguide/expectations.html#comparing-cursor-data-containing-date-fields","text":"Important note utPLSQL uses XMLType internally to represent rows of the cursor data. This is by far the most flexible method and allows comparison of cursors containing LONG, CLOB, BLOB, user defined types and even nested cursors. Due to the way Oracle handles DATE data type when converting from cursor data to XML, utPLSQL has no control over the DATE formatting. The NLS_DATE_FORMAT setting from the moment the cursor was opened determines the formatting of dates used for cursor data comparison. By default, Oracle NLS_DATE_FORMAT is timeless, so data of DATE datatype, will be compared ignoring the time component. You should use procedures ut.set_nls , ut.reset_nls around cursors that you want to compare in your tests. This way, the DATE data in cursors will be properly formatted for comparison using date-time format. The example below makes use of ut.set_nls , ut.reset_nls , so that the date in l_expected and l_actual is compared using date-time formatting. create table events ( description varchar2 ( 4000 ), event_date date ); create or replace function get_events ( a_date_from date , a_date_to date ) return sys_refcursor is l_result sys_refcursor ; begin open l_result for select description , event_date from events where event_date between a_date_from and a_date_to ; return l_result ; end ; / create or replace package test_get_events is --%suite(get_events) --%beforeall procedure setup_events ; --%test(returns event within date range) procedure get_events_for_date_range ; end ; / create or replace package body test_get_events is gc_description constant varchar2 ( 30 ) : = 'Test event' ; gc_event_date constant date : = to_date ( '2016-09-08 06:51:22' , 'yyyy-mm-dd hh24:mi:ss' ); procedure setup_events is begin insert into events ( description , event_date ) values ( gc_description , gc_event_date ); end ; procedure get_events_for_date_range is l_expected sys_refcursor ; l_actual sys_refcursor ; l_expected_bad_date sys_refcursor ; l_second number : = 1 / 24 / 60 / 60 ; begin ut . set_nls (); open l_expected for select gc_description as description , gc_event_date as event_date from dual ; open l_expected_bad_date for select gc_description as description , gc_event_date + l_second as event_date from dual ; l_actual : = get_events ( gc_event_date - 1 , gc_event_date + 1 ); ut . reset_nls (); ut . expect ( l_actual ). to_equal ( l_expected ); ut . expect ( l_actual ). not_to_equal ( l_expected_bad_date ); end ; end ; / begin ut . run (); end ; / drop table events ; drop function get_events ; drop package test_get_events ;","title":"Comparing cursor data containing DATE fields"},{"location":"userguide/expectations.html#comparing-user-defined-types-and-collections","text":"The anydata data type is used to compare user defined objects and collections. Example: create type department as object ( name varchar2 ( 30 )); / create type departments as table of department ; / create or replace package demo_dept as -- %suite(demo) --%test(demo of object to object comparison) procedure test_department ; --%test(demo of collection comparison) procedure test_departments ; end ; / create or replace package body demo_dept as procedure test_department is v_expected department ; v_actual department ; begin v_expected : = department ( 'HR' ); v_actual : = department ( 'IT' ); ut . expect ( anydata . convertObject ( v_expected ) ). to_equal ( anydata . convertObject ( v_actual ) ); end ; procedure test_department is v_expected department ; v_actual department ; begin v_expected : = departments ( department ( 'HR' )); v_actual : = departments ( department ( 'IT' )); ut . expect ( anydata . convertCollection ( v_expected ) ). to_equal ( anydata . convertCollection ( v_actual ) ); end ; end ; / This test will fail as v_actual is not equal v_expected .","title":"Comparing user defined types and collections"},{"location":"userguide/expectations.html#expecting-exceptions","text":"Below example illustrates how to write test to check for expected exceptions (thrown by tested code). create or replace procedure divide ( p_a number , p_b number ) is begin return p_a / p_b ; end ; / create or replace package test_divide is --%suite(Divide functionality) --%test(Raises exception when divisor is zero) procedure divide_raises_zero_divisor ; end ; / create or replace package body test_divide is procedure divide_raises_zero_divisor is l_my_number number ; begin l_my_number : = divide ( 1 , 0 ); -- PLSQL call throwing ORA-01476 exception ut . fail ( 'Expected exception but nothing was raised' ); exception when others then ut . expect ( sqlcode ). to_equal ( - 1476 ); ut . expect ( sqlerrm ). to_match ( 'equal to zero' ); end ; end ; / The call to ut.fail is required to make sure that the test fails, if we expect an exception, but the tested code does not throw any. The call to ut.expect uses equal matcher to check that the exception that was raised was exactly the one we were expecting to get in particular situation. Depending on the situation you will want to check for sqlcode , sqlerrm , both or perform additional expectation checks to make sure nothing was changed by the called procedure in the database.","title":"Expecting exceptions"},{"location":"userguide/expectations.html#supported-data-types","text":"The matrix below illustrates the data types supported by different matchers. be_between be_empty be_false be_greater_than be_greater_or_equal be_less_or_equal be_less_than be_like be_not_null be_null be_true equal match anydata X X X X blob X X X boolean X X X X X clob X X X X X date X X X X X X X X number X X X X X X X X refcursor X X X X timestamp X X X X X X X X timestamp with timezone X X X X X X X X timestamp with local timezone X X X X X X X X varchar2 X X X X X X interval year to month X X X X X X X X interval day to second X X X X X X X X","title":"Supported data types"},{"location":"userguide/expectations.html#negating-a-matcher","text":"Expectations provide a very convenient way to perform a check on a negated matcher. Syntax to check for matcher evaluating to true: begin ut . expect ( a_actual { data - type } ). to_ { matcher } ; ut . expect ( a_actual { data - type } ). to_ ( { matcher } ); end ; Syntax to check for matcher evaluating to false: begin ut . expect ( a_actual { data - type } ). not_to_ { matcher } ; ut . expect ( a_actual { data - type } ). not_to ( { matcher } ); end ; If a matcher evaluated to NULL, then both to_ and not_to will cause the expectation to report failure. Example: begin ut . expect ( null ). to_ ( be_true () ); ut . expect ( null ). not_to ( be_true () ); end ; Since NULL is neither true nor not true , both expectations will report failure.","title":"Negating a matcher"},{"location":"userguide/getting-started.html","text":"Getting started with TDD and utPLSQL \u00b6 utPLSQL is designed in a way that allows you to follow Test Driven Development (TDD) software development process. Below is an example of building a simple function with TDD. Gather requirements \u00b6 We have a requirement to build a function that will return a substring of a string that is passed to the function. The function should accept three parameters: input_string start_position end_position Create a test \u00b6 We will start from the bare minimum and move step by step, executing tests every time we make minimal progress. This way, we assure we don't jump ahead too much and produce code that is untested or untestable. Create test package \u00b6 create or replace package test_betwnstr as -- %suite(Between string function) end ; / Execute all tests: begin ut.run(); end; Test results: Between string function Finished in .451423 seconds 0 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) Define specification for the test \u00b6 create or replace package test_betwnstr as -- %suite(Between string function) -- %test(Returns substring from start position to end position) procedure basic_usage ; end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position (FAILED - 1) Failures: 1) basic_usage ORA-04067: not executed, package body \"UT3_USER.TEST_BETWNSTR\" does not exist ORA-06508: PL/SQL: could not find program unit being called: \"UT3_USER.TEST_BETWNSTR\" ORA-06512: at line 6 Finished in .509673 seconds 1 tests, 0 failed, 1 errored, 0 disabled, 0 warning(s) Well our test is failing as the package specification requires a body. Define body of first test \u00b6 create or replace package body test_betwnstr as procedure basic_usage is begin ut . expect ( betwnstr ( '1234567' , 2 , 5 ) ). to_equal ( '2345' ); end ; end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position (FAILED - 1) Failures: 1) basic_usage ORA-04063: package body \"UT3_USER.TEST_BETWNSTR\" has errors ORA-06508: PL/SQL: could not find program unit being called: \"UT3_USER.TEST_BETWNSTR\" ORA-06512: at line 6 Finished in .415851 seconds 1 tests, 0 failed, 1 errored, 0 disabled, 0 warning(s) Our test is failing as the test suite package body is invalid. Looks like we need to define the function we want to test. Implement code to fulfill the requirement \u00b6 Define tested function \u00b6 create or replace function betwnstr ( a_string varchar2 , a_start_pos integer , a_end_pos integer ) return varchar2 is begin return substr ( a_string , a_start_pos , a_end_pos - a_start_pos ); end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position (FAILED - 1) Failures: 1) basic_usage Actual: '234' (varchar2) was expected to equal: '2345' (varchar2) at \"\"UT3_USER.TEST_BETWNSTR\"\", line 5 Finished in .375178 seconds 1 tests, 1 failed, 0 errored, 0 disabled, 0 warning(s) So now we see that our test works but the function does not return the expected results. Let us fix this and continue from here. Fix the tested function \u00b6 The function returned a string one character short, so we need to add 1 to the substr parameter. create or replace function betwnstr ( a_string varchar2 , a_start_pos integer , a_end_pos integer ) return varchar2 is begin return substr ( a_string , a_start_pos , a_end_pos - a_start_pos + 1 ); end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position Finished in .006077 seconds 1 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) So our test is now passing, great! Refactor \u00b6 Once our tests are passing, we can safely refactor (restructure) the code as we have a safety harness in place to ensure that after the restructuring and cleanup of the code, everything is still working. One thing worth mentioning is that refactoring of tests is as important as refactoring of code. Maintainability of both is equally important. Further requirements \u00b6 It seems like our work is done. We have a function that returns a substring from start position to end position. As we move through the process of adding tests, it's very important to think about edge cases. Here is a list of edge cases for our function: start position zero input string is null start position is null end position is null start position is negative start position is bigger than end position start position is negative end position is negative We should define expected behavior for each of these edge cases. Once defined we can start implementing tests for those behaviors and adjust the tested function to meet the requirements specified in the tests. Add test for additional requirement \u00b6 A new requirement was added: Start position zero - should be treated as start position one create or replace package test_betwnstr as -- %suite(Between string function) -- %test(Returns substring from start position to end position) procedure basic_usage ; -- %test(Returns substring when start position is zero) procedure zero_start_position ; end ; / create or replace package body test_betwnstr as procedure basic_usage is begin ut . expect ( betwnstr ( '1234567' , 2 , 5 ) ). to_equal ( '2345' ); end ; procedure zero_start_position is begin ut . expect ( betwnstr ( '1234567' , 0 , 5 ) ). to_equal ( '12345' ); end ; end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position Returns substring when start position is zero (FAILED - 1) Failures: 1) zero_start_position Actual: '123456' (varchar2) was expected to equal: '12345' (varchar2) at \"\"UT3_USER.TEST_BETWNSTR\"\", line 10 Finished in .232584 seconds 2 tests, 1 failed, 0 errored, 0 disabled, 0 warning(s) Looks like our function does not work as expected for zero start position. Implementing the requirement \u00b6 Let's fix our function so that the new requirement is met create or replace function betwnstr ( a_string varchar2 , a_start_pos integer , a_end_pos integer ) return varchar2 is begin if a_start_pos = 0 then return substr ( a_string , a_start_pos , a_end_pos - a_start_pos ); else return substr ( a_string , a_start_pos , a_end_pos - a_start_pos + 1 ); end if ; end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position Returns substring when start position is zero Finished in .012718 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) Great! We have made some visible progress. Refactoring \u00b6 When all tests are passing we can proceed with a safe cleanup of our code. The function works well, but we use the return twice, which is not the best coding practice. An alternative implementation could be cleaner. create or replace function betwnstr ( a_string varchar2 , a_start_pos integer , a_end_pos integer ) return varchar2 is begin return substr ( a_string , a_start_pos , a_end_pos - greatest ( a_start_pos , 1 ) + 1 ); end ; / As we refactor we should probably run our tests as often as we compile code, so we know not only that the code compiles, but also works as expected. Between string function Returns substring from start position to end position Returns substring when start position is zero Finished in .013739 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) Remaining requirements \u00b6 You may continue on with the remaining edge cases from here. identify requirement define requirement with test run test to check if requirement is met implement code to meet requirement run test to check if requirement is met refactor/cleanup code and tests Hope you will enjoy it as much as we do.","title":"Getting Started"},{"location":"userguide/getting-started.html#getting-started-with-tdd-and-utplsql","text":"utPLSQL is designed in a way that allows you to follow Test Driven Development (TDD) software development process. Below is an example of building a simple function with TDD.","title":"Getting started with TDD and utPLSQL"},{"location":"userguide/getting-started.html#gather-requirements","text":"We have a requirement to build a function that will return a substring of a string that is passed to the function. The function should accept three parameters: input_string start_position end_position","title":"Gather requirements"},{"location":"userguide/getting-started.html#create-a-test","text":"We will start from the bare minimum and move step by step, executing tests every time we make minimal progress. This way, we assure we don't jump ahead too much and produce code that is untested or untestable.","title":"Create a test"},{"location":"userguide/getting-started.html#create-test-package","text":"create or replace package test_betwnstr as -- %suite(Between string function) end ; / Execute all tests: begin ut.run(); end; Test results: Between string function Finished in .451423 seconds 0 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s)","title":"Create test package"},{"location":"userguide/getting-started.html#define-specification-for-the-test","text":"create or replace package test_betwnstr as -- %suite(Between string function) -- %test(Returns substring from start position to end position) procedure basic_usage ; end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position (FAILED - 1) Failures: 1) basic_usage ORA-04067: not executed, package body \"UT3_USER.TEST_BETWNSTR\" does not exist ORA-06508: PL/SQL: could not find program unit being called: \"UT3_USER.TEST_BETWNSTR\" ORA-06512: at line 6 Finished in .509673 seconds 1 tests, 0 failed, 1 errored, 0 disabled, 0 warning(s) Well our test is failing as the package specification requires a body.","title":"Define specification for the test"},{"location":"userguide/getting-started.html#define-body-of-first-test","text":"create or replace package body test_betwnstr as procedure basic_usage is begin ut . expect ( betwnstr ( '1234567' , 2 , 5 ) ). to_equal ( '2345' ); end ; end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position (FAILED - 1) Failures: 1) basic_usage ORA-04063: package body \"UT3_USER.TEST_BETWNSTR\" has errors ORA-06508: PL/SQL: could not find program unit being called: \"UT3_USER.TEST_BETWNSTR\" ORA-06512: at line 6 Finished in .415851 seconds 1 tests, 0 failed, 1 errored, 0 disabled, 0 warning(s) Our test is failing as the test suite package body is invalid. Looks like we need to define the function we want to test.","title":"Define body of first test"},{"location":"userguide/getting-started.html#implement-code-to-fulfill-the-requirement","text":"","title":"Implement code to fulfill the requirement"},{"location":"userguide/getting-started.html#define-tested-function","text":"create or replace function betwnstr ( a_string varchar2 , a_start_pos integer , a_end_pos integer ) return varchar2 is begin return substr ( a_string , a_start_pos , a_end_pos - a_start_pos ); end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position (FAILED - 1) Failures: 1) basic_usage Actual: '234' (varchar2) was expected to equal: '2345' (varchar2) at \"\"UT3_USER.TEST_BETWNSTR\"\", line 5 Finished in .375178 seconds 1 tests, 1 failed, 0 errored, 0 disabled, 0 warning(s) So now we see that our test works but the function does not return the expected results. Let us fix this and continue from here.","title":"Define tested function"},{"location":"userguide/getting-started.html#fix-the-tested-function","text":"The function returned a string one character short, so we need to add 1 to the substr parameter. create or replace function betwnstr ( a_string varchar2 , a_start_pos integer , a_end_pos integer ) return varchar2 is begin return substr ( a_string , a_start_pos , a_end_pos - a_start_pos + 1 ); end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position Finished in .006077 seconds 1 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) So our test is now passing, great!","title":"Fix the tested function"},{"location":"userguide/getting-started.html#refactor","text":"Once our tests are passing, we can safely refactor (restructure) the code as we have a safety harness in place to ensure that after the restructuring and cleanup of the code, everything is still working. One thing worth mentioning is that refactoring of tests is as important as refactoring of code. Maintainability of both is equally important.","title":"Refactor"},{"location":"userguide/getting-started.html#further-requirements","text":"It seems like our work is done. We have a function that returns a substring from start position to end position. As we move through the process of adding tests, it's very important to think about edge cases. Here is a list of edge cases for our function: start position zero input string is null start position is null end position is null start position is negative start position is bigger than end position start position is negative end position is negative We should define expected behavior for each of these edge cases. Once defined we can start implementing tests for those behaviors and adjust the tested function to meet the requirements specified in the tests.","title":"Further requirements"},{"location":"userguide/getting-started.html#add-test-for-additional-requirement","text":"A new requirement was added: Start position zero - should be treated as start position one create or replace package test_betwnstr as -- %suite(Between string function) -- %test(Returns substring from start position to end position) procedure basic_usage ; -- %test(Returns substring when start position is zero) procedure zero_start_position ; end ; / create or replace package body test_betwnstr as procedure basic_usage is begin ut . expect ( betwnstr ( '1234567' , 2 , 5 ) ). to_equal ( '2345' ); end ; procedure zero_start_position is begin ut . expect ( betwnstr ( '1234567' , 0 , 5 ) ). to_equal ( '12345' ); end ; end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position Returns substring when start position is zero (FAILED - 1) Failures: 1) zero_start_position Actual: '123456' (varchar2) was expected to equal: '12345' (varchar2) at \"\"UT3_USER.TEST_BETWNSTR\"\", line 10 Finished in .232584 seconds 2 tests, 1 failed, 0 errored, 0 disabled, 0 warning(s) Looks like our function does not work as expected for zero start position.","title":"Add test for additional requirement"},{"location":"userguide/getting-started.html#implementing-the-requirement","text":"Let's fix our function so that the new requirement is met create or replace function betwnstr ( a_string varchar2 , a_start_pos integer , a_end_pos integer ) return varchar2 is begin if a_start_pos = 0 then return substr ( a_string , a_start_pos , a_end_pos - a_start_pos ); else return substr ( a_string , a_start_pos , a_end_pos - a_start_pos + 1 ); end if ; end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position Returns substring when start position is zero Finished in .012718 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) Great! We have made some visible progress.","title":"Implementing the requirement"},{"location":"userguide/getting-started.html#refactoring","text":"When all tests are passing we can proceed with a safe cleanup of our code. The function works well, but we use the return twice, which is not the best coding practice. An alternative implementation could be cleaner. create or replace function betwnstr ( a_string varchar2 , a_start_pos integer , a_end_pos integer ) return varchar2 is begin return substr ( a_string , a_start_pos , a_end_pos - greatest ( a_start_pos , 1 ) + 1 ); end ; / As we refactor we should probably run our tests as often as we compile code, so we know not only that the code compiles, but also works as expected. Between string function Returns substring from start position to end position Returns substring when start position is zero Finished in .013739 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s)","title":"Refactoring"},{"location":"userguide/getting-started.html#remaining-requirements","text":"You may continue on with the remaining edge cases from here. identify requirement define requirement with test run test to check if requirement is met implement code to meet requirement run test to check if requirement is met refactor/cleanup code and tests Hope you will enjoy it as much as we do.","title":"Remaining requirements"},{"location":"userguide/install.html","text":"Downloading latest version of utPLSQL \u00b6 It is quite easy to download latest version of utPLSQL from github on both Unix/Linux as well as Windows machines. Below are little snippets that can be handy for downloading latest version. Unix/Linux \u00b6 #!/bin/bash # Get the url to latest release \"zip\" file UTPLSQL_DOWNLOAD_URL = $( curl --silent https://api.github.com/repos/utPLSQL/utPLSQL/releases/latest | awk '/browser_download_url/ { print $2 }' | grep \".zip\" | sed 's/\"//g' ) # Download the latest release \"zip\" file curl -Lk \" ${ UTPLSQL_DOWNLOAD_URL } \" -o utPLSQL.zip # Extract downloaded \"zip\" file unzip -q utPLSQL.zip You may download with a one-liner if that is more convenient. #!/bin/bash curl -LOk $( curl --silent https://api.github.com/repos/utPLSQL/utPLSQL/releases/latest | awk '/browser_download_url/ { print $2 }' | grep \".zip\" | sed 's/\"//g' ) Windows \u00b6 To run the script on windows you will need PowerShell 3.0 or above. You will also need .NET 4.0 Framework or above. $archiveName = 'utPLSQL.zip' $latestRepo = Invoke-WebRequest https://api.github.com/repos/utPLSQL/utPLSQL/releases/latest $repo = $latestRepo.Content | Convertfrom-Json $urlList = $repo.assets.browser_download_url Add-Type -assembly \"system.io.compression.filesystem\" foreach ($i in $urlList) { $fileName = $i.substring($i.LastIndexOf( \"/\" ) + 1) if ( $fileName.substring($fileName.LastIndexOf(\".\") + 1) -eq 'zip' ) { Invoke-WebRequest $i -OutFile $archiveName $fileLocation = Get-ChildItem | where {$_.Name -eq $archiveName} if ($fileLocation) { [io.compression.zipfile]::ExtractToDirectory($($fileLocation.FullName),$($fileLocation.DirectoryName)) } } } Headless installation \u00b6 To simply install the utPLSQL into a new database schema and grant it to public, execute the script install_headless.sql as SYSDBA. This will create a new user UT3 with password XNtxj8eEgA6X6b6f , grant all needed privileges to that user and create PUBLIC synonyms needed to use the utPLSQL framework. Example invocation of the script from command line: cd source sqlplus sys/sys_pass@db as sysdba @@install_headless.sql SYSDBA is needed to grant access to DBMS_LOCK. Recommended Schema \u00b6 It is recommended to install utPLSQL in it's own schema. You are free to choose any name for this schema. The installation user/schema must have the following Oracle system permissions during the installation. CREATE SESSION CREATE PROCEDURE CREATE TYPE CREATE TABLE CREATE VIEW CREATE SYNONYM ALTER SESSION In addition it must be granted execute to the following system packages. DBMS_LOCK utPLSQL is using DBMS_PROFILER tables for code coverage. The tables required by DBMS_PROFILER will be created in the installation schema unless they already exist. The uninstall process will not drop profiler tables, as they can potentially be shared and reused for profiling PLSQL code. It is up to DBA to maintain the storage of the profiler tables. Installation Procedure \u00b6 Creating schema for utPLSQL \u00b6 To create the utPLSQL schema and grant all the needed privileges execute script create_utplsql_owner.sql from the source directory with parameters: user name - the name of the user that will own of utPLSQL object password - the password to be set for that user tablespace name - the tablespace name to hold data created during test execution Example invocation: cd source sqlplus sys/sys_password@database as sysdba @create_utPLSQL_owner.sql ut3 ut3 users Installing utPLSQL \u00b6 To install the utPLSQL framework into your database run the /source/install.sql script and provide schema_name where utPLSQL is to be installed. Schema must be created prior to calling the install script. You may install utPLSQL from any account that has sufficient privileges to create objects in other users schema. Example invocation: cd source sqlplus admin/admins_password@database @install.sql ut3 Allowing other users to access utPLSQL framework \u00b6 In order to allow other users to access utPLSQL, synonyms must be created and grants need to be added. You have two options: use grants and synonyms to public, to allow all users to access the framework use synonyms and grants for individual users to limit the access to the framework To grant utPLSQL to public execute script source/create_synonyms_and_grants_for_public.sql and provide schema_name where utPLSQL is installed. Example invocation: cd source sqlplus admin/admins_password@database @create_synonyms_and_grants_for_public.sql ut3 To grant utPLSQL to individual user execute script source/create_synonyms_and_grants_for_user.sql , provide schema_name where utPLSQL is installed and user_name to grant access for. Example invocation: cd source sqlplus admin/admins_password@database @create_synonyms_and_grants_for_user.sql ut3 hr The following tools that support the SQL*Plus commands can be used to run the installation script: SQL*Plus SQLcl Oracle SQL Developer Additional requirements \u00b6 In order to use Code Coverage functionality of utPLSQL, users executing the tests must have the CREATE privilege on the PLSQL code that the coverage is gathered on. This is a requirement of DBMS_PROFILER package . In practice, user running tests for PLSQL code that he does not own, needs to have CREATE ANY PROCEDURE/CREATE ANY TRIGGER privileges. Running code coverage on objects that the user does not own will not produce any coverage information without those privileges. Uninstalling utPLSQL \u00b6 To uninstall run /source/uninstall.sql and provide schema_name where utPLSQL is installed. The uninstall script will remove all the objects installed by the install script. Additionally, all the public and private synonyms pointing to the objects in utPLSQL schema will be removed. If you have you have extended any utPLSQL types such as a custom reporter, these will need to be dropped before the uninstall, otherwise the uninstall script might fail. In order for the uninstall to be successful, you need to use the uninstall script, that was provided whit the exact version that was installed on your database. The uninstall script provided with version 3.0.1 will probably not work, if you want to remove version 3.0.0 from your database. Version upgrade \u00b6 Currently, the only way to upgrade version of utPLSQL v3.0.0 and above is to remove the previous version and install new version Working with utPLSQL v2 \u00b6 If you are using utPLSQL v2, you can still install utPLSQL v3. The only requirement is that utPLSQL v3 needs to be installed in different schema than utPLSQL v2. utPLSQL v3 and utPLSQL v2 do not collide on public synonym names.","title":"Installation"},{"location":"userguide/install.html#downloading-latest-version-of-utplsql","text":"It is quite easy to download latest version of utPLSQL from github on both Unix/Linux as well as Windows machines. Below are little snippets that can be handy for downloading latest version.","title":"Downloading latest version of utPLSQL"},{"location":"userguide/install.html#unixlinux","text":"#!/bin/bash # Get the url to latest release \"zip\" file UTPLSQL_DOWNLOAD_URL = $( curl --silent https://api.github.com/repos/utPLSQL/utPLSQL/releases/latest | awk '/browser_download_url/ { print $2 }' | grep \".zip\" | sed 's/\"//g' ) # Download the latest release \"zip\" file curl -Lk \" ${ UTPLSQL_DOWNLOAD_URL } \" -o utPLSQL.zip # Extract downloaded \"zip\" file unzip -q utPLSQL.zip You may download with a one-liner if that is more convenient. #!/bin/bash curl -LOk $( curl --silent https://api.github.com/repos/utPLSQL/utPLSQL/releases/latest | awk '/browser_download_url/ { print $2 }' | grep \".zip\" | sed 's/\"//g' )","title":"Unix/Linux"},{"location":"userguide/install.html#windows","text":"To run the script on windows you will need PowerShell 3.0 or above. You will also need .NET 4.0 Framework or above. $archiveName = 'utPLSQL.zip' $latestRepo = Invoke-WebRequest https://api.github.com/repos/utPLSQL/utPLSQL/releases/latest $repo = $latestRepo.Content | Convertfrom-Json $urlList = $repo.assets.browser_download_url Add-Type -assembly \"system.io.compression.filesystem\" foreach ($i in $urlList) { $fileName = $i.substring($i.LastIndexOf( \"/\" ) + 1) if ( $fileName.substring($fileName.LastIndexOf(\".\") + 1) -eq 'zip' ) { Invoke-WebRequest $i -OutFile $archiveName $fileLocation = Get-ChildItem | where {$_.Name -eq $archiveName} if ($fileLocation) { [io.compression.zipfile]::ExtractToDirectory($($fileLocation.FullName),$($fileLocation.DirectoryName)) } } }","title":"Windows"},{"location":"userguide/install.html#headless-installation","text":"To simply install the utPLSQL into a new database schema and grant it to public, execute the script install_headless.sql as SYSDBA. This will create a new user UT3 with password XNtxj8eEgA6X6b6f , grant all needed privileges to that user and create PUBLIC synonyms needed to use the utPLSQL framework. Example invocation of the script from command line: cd source sqlplus sys/sys_pass@db as sysdba @@install_headless.sql SYSDBA is needed to grant access to DBMS_LOCK.","title":"Headless installation"},{"location":"userguide/install.html#recommended-schema","text":"It is recommended to install utPLSQL in it's own schema. You are free to choose any name for this schema. The installation user/schema must have the following Oracle system permissions during the installation. CREATE SESSION CREATE PROCEDURE CREATE TYPE CREATE TABLE CREATE VIEW CREATE SYNONYM ALTER SESSION In addition it must be granted execute to the following system packages. DBMS_LOCK utPLSQL is using DBMS_PROFILER tables for code coverage. The tables required by DBMS_PROFILER will be created in the installation schema unless they already exist. The uninstall process will not drop profiler tables, as they can potentially be shared and reused for profiling PLSQL code. It is up to DBA to maintain the storage of the profiler tables.","title":"Recommended Schema"},{"location":"userguide/install.html#installation-procedure","text":"","title":"Installation Procedure"},{"location":"userguide/install.html#creating-schema-for-utplsql","text":"To create the utPLSQL schema and grant all the needed privileges execute script create_utplsql_owner.sql from the source directory with parameters: user name - the name of the user that will own of utPLSQL object password - the password to be set for that user tablespace name - the tablespace name to hold data created during test execution Example invocation: cd source sqlplus sys/sys_password@database as sysdba @create_utPLSQL_owner.sql ut3 ut3 users","title":"Creating schema for utPLSQL"},{"location":"userguide/install.html#installing-utplsql","text":"To install the utPLSQL framework into your database run the /source/install.sql script and provide schema_name where utPLSQL is to be installed. Schema must be created prior to calling the install script. You may install utPLSQL from any account that has sufficient privileges to create objects in other users schema. Example invocation: cd source sqlplus admin/admins_password@database @install.sql ut3","title":"Installing utPLSQL"},{"location":"userguide/install.html#allowing-other-users-to-access-utplsql-framework","text":"In order to allow other users to access utPLSQL, synonyms must be created and grants need to be added. You have two options: use grants and synonyms to public, to allow all users to access the framework use synonyms and grants for individual users to limit the access to the framework To grant utPLSQL to public execute script source/create_synonyms_and_grants_for_public.sql and provide schema_name where utPLSQL is installed. Example invocation: cd source sqlplus admin/admins_password@database @create_synonyms_and_grants_for_public.sql ut3 To grant utPLSQL to individual user execute script source/create_synonyms_and_grants_for_user.sql , provide schema_name where utPLSQL is installed and user_name to grant access for. Example invocation: cd source sqlplus admin/admins_password@database @create_synonyms_and_grants_for_user.sql ut3 hr The following tools that support the SQL*Plus commands can be used to run the installation script: SQL*Plus SQLcl Oracle SQL Developer","title":"Allowing other users to access utPLSQL framework"},{"location":"userguide/install.html#additional-requirements","text":"In order to use Code Coverage functionality of utPLSQL, users executing the tests must have the CREATE privilege on the PLSQL code that the coverage is gathered on. This is a requirement of DBMS_PROFILER package . In practice, user running tests for PLSQL code that he does not own, needs to have CREATE ANY PROCEDURE/CREATE ANY TRIGGER privileges. Running code coverage on objects that the user does not own will not produce any coverage information without those privileges.","title":"Additional requirements"},{"location":"userguide/install.html#uninstalling-utplsql","text":"To uninstall run /source/uninstall.sql and provide schema_name where utPLSQL is installed. The uninstall script will remove all the objects installed by the install script. Additionally, all the public and private synonyms pointing to the objects in utPLSQL schema will be removed. If you have you have extended any utPLSQL types such as a custom reporter, these will need to be dropped before the uninstall, otherwise the uninstall script might fail. In order for the uninstall to be successful, you need to use the uninstall script, that was provided whit the exact version that was installed on your database. The uninstall script provided with version 3.0.1 will probably not work, if you want to remove version 3.0.0 from your database.","title":"Uninstalling utPLSQL"},{"location":"userguide/install.html#version-upgrade","text":"Currently, the only way to upgrade version of utPLSQL v3.0.0 and above is to remove the previous version and install new version","title":"Version upgrade"},{"location":"userguide/install.html#working-with-utplsql-v2","text":"If you are using utPLSQL v2, you can still install utPLSQL v3. The only requirement is that utPLSQL v3 needs to be installed in different schema than utPLSQL v2. utPLSQL v3 and utPLSQL v2 do not collide on public synonym names.","title":"Working with utPLSQL v2"},{"location":"userguide/reporters.html","text":"utPLSQL provides the following reporting formats. Documentation reporter \u00b6 The ut_documentation_reporter is the default reporting format used by the framework. It provides a human readable test results. To invoke tests with documentation reporter use one of following calls from sql console (SQLPlus) exec ut.run(); exec ut.run(ut_documentation_reporter()); You may also invoke unit tests directly from command line by calling. ut_run user/pass@dbsid Invoking tests from command line tool ut_run allows you to track progress of test execution. In that case, the documentation reporter will provide information about each test that was executed as soon as it's execution finishes. For more details on using the ut_run script look into utPLSQL-sql-cli project. The ut_documentation_reporter doesn't accept any arguments. Example outputs from documentation reporter. The documentation report provides the following information. - Test suite name or test package name (nested with suitepath if suitepath is used) - Test description name or test procedure name - Information about test failing (FAILED - n) - Information about disabled test (IGNORED) - List of all errors and failures - Summary with total number of tests, number of tests with status and timing for the execution Color output from documentation reporter \u00b6 When invoking tests with documentation reporter and your command line supports ANSICONSOLE (default on Unix) available for Windows , you can obtain the coloured outputs from the documentation reporter. To invoke tests with documentation reporter in color mode use one of following calls. exec ut.run(a_color_console=>true); exec ut.run(ut_documentation_reporter(), a_color_console=>true); Example outputs from documentation reporter. XUnit reporter \u00b6 Most of continuous integration servers (like Jenkins) are capable of consuming unit test execution results in XUnit/JUnit format. The ut_xunit_reporter is producing outcomes as XUnit-compatible XML unit test report, that can be used by CI servers to display their custom reports and provide metrics (like tests execution trends). Invocation of tests with XUnit reporter. exec ut.run(ut_xunit_reporter()); The ut_xunit_reporter doesn't accept any arguments. Example of xunit report integrated with Jenkins CI Example of failure report details Teamcity reporter \u00b6 Teamcity is a CI server by Jetbrains. It supports XUnit reporting and additionally has it's own format of reporting that allows tracking of progress of a CI step/task as it executes. The TeamCity format developed by Jetbrains is supported by utPLSQL with ut_teamcity_reporter . Invocation of tests with Teamcity reporter. exec ut.run(ut_teamcity_reporter()); The ut_teamcity_reporter doesn't accept any arguments. Example of unit test report from Teamcity CI server. Example of failure report details Sonar test reporter \u00b6 If you are using SonarQube to do static code analysis for you PLSQL projects, your code analysis can benefit from code coverage and test results. utPLSQL provides two reporters to for SonarQube: - ut_sonar_test_reporter - provides an XML output of each test executed per each project test file (package) - ut_coverage_sonar_reporter - provides XML output of code coverage per each project source file ut_sonar_test_reporter needs to be called with a list of paths to test files (packages). The paths to files can be relative to the project root directory (recommended) or be absolute. ut_coverage_sonar_reporter needs to be called with a list of paths to source files for your project. The paths to files can be relative to the project root directory (recommended) or be absolute. Providing invalid paths or paths to non-existing files will result in failure when publishing test results/coverage results to sonar server. For details on how to invoke reporter with paths, see the Coverage reporters section. Coverage reporters \u00b6 utPLSQL comes with a set of build-in coverage reporters. Have a look into the coverage documentation to learn more about them.","title":"Using reporters"},{"location":"userguide/reporters.html#documentation-reporter","text":"The ut_documentation_reporter is the default reporting format used by the framework. It provides a human readable test results. To invoke tests with documentation reporter use one of following calls from sql console (SQLPlus) exec ut.run(); exec ut.run(ut_documentation_reporter()); You may also invoke unit tests directly from command line by calling. ut_run user/pass@dbsid Invoking tests from command line tool ut_run allows you to track progress of test execution. In that case, the documentation reporter will provide information about each test that was executed as soon as it's execution finishes. For more details on using the ut_run script look into utPLSQL-sql-cli project. The ut_documentation_reporter doesn't accept any arguments. Example outputs from documentation reporter. The documentation report provides the following information. - Test suite name or test package name (nested with suitepath if suitepath is used) - Test description name or test procedure name - Information about test failing (FAILED - n) - Information about disabled test (IGNORED) - List of all errors and failures - Summary with total number of tests, number of tests with status and timing for the execution","title":"Documentation reporter"},{"location":"userguide/reporters.html#color-output-from-documentation-reporter","text":"When invoking tests with documentation reporter and your command line supports ANSICONSOLE (default on Unix) available for Windows , you can obtain the coloured outputs from the documentation reporter. To invoke tests with documentation reporter in color mode use one of following calls. exec ut.run(a_color_console=>true); exec ut.run(ut_documentation_reporter(), a_color_console=>true); Example outputs from documentation reporter.","title":"Color output from documentation reporter"},{"location":"userguide/reporters.html#xunit-reporter","text":"Most of continuous integration servers (like Jenkins) are capable of consuming unit test execution results in XUnit/JUnit format. The ut_xunit_reporter is producing outcomes as XUnit-compatible XML unit test report, that can be used by CI servers to display their custom reports and provide metrics (like tests execution trends). Invocation of tests with XUnit reporter. exec ut.run(ut_xunit_reporter()); The ut_xunit_reporter doesn't accept any arguments. Example of xunit report integrated with Jenkins CI Example of failure report details","title":"XUnit reporter"},{"location":"userguide/reporters.html#teamcity-reporter","text":"Teamcity is a CI server by Jetbrains. It supports XUnit reporting and additionally has it's own format of reporting that allows tracking of progress of a CI step/task as it executes. The TeamCity format developed by Jetbrains is supported by utPLSQL with ut_teamcity_reporter . Invocation of tests with Teamcity reporter. exec ut.run(ut_teamcity_reporter()); The ut_teamcity_reporter doesn't accept any arguments. Example of unit test report from Teamcity CI server. Example of failure report details","title":"Teamcity reporter"},{"location":"userguide/reporters.html#sonar-test-reporter","text":"If you are using SonarQube to do static code analysis for you PLSQL projects, your code analysis can benefit from code coverage and test results. utPLSQL provides two reporters to for SonarQube: - ut_sonar_test_reporter - provides an XML output of each test executed per each project test file (package) - ut_coverage_sonar_reporter - provides XML output of code coverage per each project source file ut_sonar_test_reporter needs to be called with a list of paths to test files (packages). The paths to files can be relative to the project root directory (recommended) or be absolute. ut_coverage_sonar_reporter needs to be called with a list of paths to source files for your project. The paths to files can be relative to the project root directory (recommended) or be absolute. Providing invalid paths or paths to non-existing files will result in failure when publishing test results/coverage results to sonar server. For details on how to invoke reporter with paths, see the Coverage reporters section.","title":"Sonar test reporter"},{"location":"userguide/reporters.html#coverage-reporters","text":"utPLSQL comes with a set of build-in coverage reporters. Have a look into the coverage documentation to learn more about them.","title":"Coverage reporters"},{"location":"userguide/running-unit-tests.html","text":"Running tests \u00b6 The utPLSQL framework provides two main entry points to run unit tests from within the database: ut.run procedures and functions ut_runner.run procedures These two entry points differ in purpose and behavior. Most of the time you will want to use ut.run as ut_runner is designed for API integration and does not output the results to the screen directly. utPLSQL-sql-cli \u00b6 If you are considering running your tests from a command line or from a CI server like Jenkins/Teamcity, the best way is to use the utPLSQL-sql-cli . You may download the latest release of the command line client automatically using the command below (Unix). #!/bin/bash # Get the url to latest release \"zip\" file DOWNLOAD_URL = $( curl --silent https://api.github.com/repos/utPLSQL/utPLSQL-sql-cli/releases/latest | awk '/zipball_url/ { print $2 }' | sed -r 's/\"|,//g' ) # Download the latest release \"zip\" file curl -Lk \" ${ DOWNLOAD_URL } \" -o utplsql-sql-cli.zip # Extract downloaded \"zip\" file unzip -q utplsql-sql-cli.zip ut.run \u00b6 The ut package contains overloaded run procedures and functions. The run API is designed to be called directly by a developer when using an IDE/SQL console to execute unit tests. The main benefit of using this API is it's simplicity. A single line call is enough to execute a set of tests from one or more schemes. The procedures execute the specified tests and produce output to DBMS_OUTPUT using the specified reporter. The functions can only be used in SELECT statements. They execute the specified tests and produce outputs as a pipelined data stream to be consumed by a select statement. ut.run procedures \u00b6 The examples below illustrate different ways and options to invoke ut.run procedures. alter session set current_schema = hr ; begin ut . run (); end ; Executes all tests in current schema ( HR ). begin ut . run ( 'HR' ); end ; Executes all tests in specified schema ( HR ). begin ut . run ( 'hr:com.my_org.my_project' ); end ; Executes all tests from all packages that are on the com.my_org.my_project suitepath. Check the annotations documentation to find out about suitepaths and how they can be used to organize test packages for your project. begin ut . run ( 'hr.test_apply_bonus' ); end ; Executes all tests from package hr.test_apply_bonus . begin ut . run ( 'hr.test_apply_bonus.bonus_cannot_be_negative' ); end ; Executes single test procedure hr.test_apply_bonus.bonus_cannot_be_negative . begin ut . run ( ut_varchar2_list ( 'hr.test_apply_bonus' , 'cust' )); end ; Executes all tests from package hr.test_apply_bonus and all tests from schema cust . Using a list of items to execute allows you to execute a fine-grained set of tests. Note: ut_documentation_reporter is the default reporter for all APIs defined for running unit tests. The ut.run procedures and functions accept a_reporter attribute that defines the reporter to be used in the run. You can execute any set of tests with any of the predefined reporters. begin ut . run ( 'hr.test_apply_bonus' , ut_xunit_reporter ()); end ; Executes all tests from package HR.TEST_APPLY_BONUS and provide outputs to DBMS_OUTPUT using the XUnit reporter. For details on build-in reporters look at reporters documentation . ut.run functions \u00b6 The ut.run functions provide exactly the same functionality as the ut.run procedures. You may use the same sets of parameters with both functions and procedures. The only difference is the output of the results. Functions provide output as a pipelined stream and therefore need to be executed as select statements. Example. select * from table ( ut . run ( 'hr.test_apply_bonus' , ut_xunit_reporter ())); ut_runner.run procedures \u00b6 The ut_runner package provides an API for integrating utPLSQL with other products. Maven, Jenkins, SQL Develper, PL/SQL Developer, TOAD and others can leverage this API to call utPLSQL. The main difference compared to the ut.run API is that ut_runner.run does not print output to the screen. ut_runner.run accepts multiple reporters. Each reporter pipes to a separate output (uniquely identified by output_id). Outputs of multiple reporters can be consumed in parallel. This allows for live reporting of test execution progress with threads and several database sessions. The concept is pretty simple. in the main thread (session), define the reporters to be used. Each reporter has it's output_id and so you need to extract and store those output_ids. as a separate thread, start ut_runner.run and pass reporters with previously defined output_ids. for each reporter start a separate thread and read outputs from the ut_output_buffer.get_lines table function by providing the output_id defined in the main thread.","title":"Running unit tests"},{"location":"userguide/running-unit-tests.html#running-tests","text":"The utPLSQL framework provides two main entry points to run unit tests from within the database: ut.run procedures and functions ut_runner.run procedures These two entry points differ in purpose and behavior. Most of the time you will want to use ut.run as ut_runner is designed for API integration and does not output the results to the screen directly.","title":"Running tests"},{"location":"userguide/running-unit-tests.html#utplsql-sql-cli","text":"If you are considering running your tests from a command line or from a CI server like Jenkins/Teamcity, the best way is to use the utPLSQL-sql-cli . You may download the latest release of the command line client automatically using the command below (Unix). #!/bin/bash # Get the url to latest release \"zip\" file DOWNLOAD_URL = $( curl --silent https://api.github.com/repos/utPLSQL/utPLSQL-sql-cli/releases/latest | awk '/zipball_url/ { print $2 }' | sed -r 's/\"|,//g' ) # Download the latest release \"zip\" file curl -Lk \" ${ DOWNLOAD_URL } \" -o utplsql-sql-cli.zip # Extract downloaded \"zip\" file unzip -q utplsql-sql-cli.zip","title":"utPLSQL-sql-cli"},{"location":"userguide/running-unit-tests.html#utrun","text":"The ut package contains overloaded run procedures and functions. The run API is designed to be called directly by a developer when using an IDE/SQL console to execute unit tests. The main benefit of using this API is it's simplicity. A single line call is enough to execute a set of tests from one or more schemes. The procedures execute the specified tests and produce output to DBMS_OUTPUT using the specified reporter. The functions can only be used in SELECT statements. They execute the specified tests and produce outputs as a pipelined data stream to be consumed by a select statement.","title":"ut.run"},{"location":"userguide/running-unit-tests.html#utrun-procedures","text":"The examples below illustrate different ways and options to invoke ut.run procedures. alter session set current_schema = hr ; begin ut . run (); end ; Executes all tests in current schema ( HR ). begin ut . run ( 'HR' ); end ; Executes all tests in specified schema ( HR ). begin ut . run ( 'hr:com.my_org.my_project' ); end ; Executes all tests from all packages that are on the com.my_org.my_project suitepath. Check the annotations documentation to find out about suitepaths and how they can be used to organize test packages for your project. begin ut . run ( 'hr.test_apply_bonus' ); end ; Executes all tests from package hr.test_apply_bonus . begin ut . run ( 'hr.test_apply_bonus.bonus_cannot_be_negative' ); end ; Executes single test procedure hr.test_apply_bonus.bonus_cannot_be_negative . begin ut . run ( ut_varchar2_list ( 'hr.test_apply_bonus' , 'cust' )); end ; Executes all tests from package hr.test_apply_bonus and all tests from schema cust . Using a list of items to execute allows you to execute a fine-grained set of tests. Note: ut_documentation_reporter is the default reporter for all APIs defined for running unit tests. The ut.run procedures and functions accept a_reporter attribute that defines the reporter to be used in the run. You can execute any set of tests with any of the predefined reporters. begin ut . run ( 'hr.test_apply_bonus' , ut_xunit_reporter ()); end ; Executes all tests from package HR.TEST_APPLY_BONUS and provide outputs to DBMS_OUTPUT using the XUnit reporter. For details on build-in reporters look at reporters documentation .","title":"ut.run procedures"},{"location":"userguide/running-unit-tests.html#utrun-functions","text":"The ut.run functions provide exactly the same functionality as the ut.run procedures. You may use the same sets of parameters with both functions and procedures. The only difference is the output of the results. Functions provide output as a pipelined stream and therefore need to be executed as select statements. Example. select * from table ( ut . run ( 'hr.test_apply_bonus' , ut_xunit_reporter ()));","title":"ut.run functions"},{"location":"userguide/running-unit-tests.html#ut_runnerrun-procedures","text":"The ut_runner package provides an API for integrating utPLSQL with other products. Maven, Jenkins, SQL Develper, PL/SQL Developer, TOAD and others can leverage this API to call utPLSQL. The main difference compared to the ut.run API is that ut_runner.run does not print output to the screen. ut_runner.run accepts multiple reporters. Each reporter pipes to a separate output (uniquely identified by output_id). Outputs of multiple reporters can be consumed in parallel. This allows for live reporting of test execution progress with threads and several database sessions. The concept is pretty simple. in the main thread (session), define the reporters to be used. Each reporter has it's output_id and so you need to extract and store those output_ids. as a separate thread, start ut_runner.run and pass reporters with previously defined output_ids. for each reporter start a separate thread and read outputs from the ut_output_buffer.get_lines table function by providing the output_id defined in the main thread.","title":"ut_runner.run procedures"},{"location":"userguide/upgrade.html","text":"Upgrading from version 2 \u00b6 utPLSQL v3 is a total rewrite of the framework. To make utPLSQL v2 packages run on v3 framework you need to install and execute migration utility. See the utPLSQL-v2-v3-migration project for details on how to install and execute the migration.","title":"Upgrade utPLSQL"},{"location":"userguide/upgrade.html#upgrading-from-version-2","text":"utPLSQL v3 is a total rewrite of the framework. To make utPLSQL v2 packages run on v3 framework you need to install and execute migration utility. See the utPLSQL-v2-v3-migration project for details on how to install and execute the migration.","title":"Upgrading from version 2"}]}